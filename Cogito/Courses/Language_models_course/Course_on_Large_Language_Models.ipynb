{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/CogitoNTNU/course-on-large-language-models/blob/main/Course_on_Large_Language_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sGjEWSy1FrY"
      },
      "source": [
        "# Course on Large Language Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGJkS1ctKNvq"
      },
      "source": [
        "**NOTE:** You're only meant to change code marked with \"# TODO:\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEKMx87cR105"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. **Setting Up**\n",
        "    - API Key Configuration\n",
        "    - Connecting to OpenAI API\n",
        "2. **Exploring the API**\n",
        "    - Creating Chat Completions\n",
        "    - Understanding Completion Parameters\n",
        "3. **Prompt Engineering**\n",
        "    - Crafting Effective Prompts\n",
        "    - Strategies and Best Practices\n",
        "4. **Advanced Techniques**\n",
        "    - Utilizing Embeddings\n",
        "    - Function Calling in LLMs\n",
        "5. **Extras**\n",
        "    - Creating an API key\n",
        "    - Local Development with LLMs\n",
        "    - Context Windows\n",
        "    - Fine-Tuning LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSiOx5S_DYlf"
      },
      "source": [
        "## Part 0: Setup\n",
        "To be able to use OpenAI one needs to configure an API key to the be allowed responses to requests. Remember not to commit this key to any repository or upload it as OpenAI will disable the key if it is found, and others can use it to make requests that you or your organisation (Cogito) will pay for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LlRpazpLEtP2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.99.6-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai)\n",
            "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "     ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 68.0/68.0 kB 1.8 MB/s eta 0:00:00\n",
            "Collecting sniffio (from openai)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 57.7/57.7 kB 3.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.14.1)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Downloading openai-1.99.6-py3-none-any.whl (786 kB)\n",
            "   ---------------------------------------- 0.0/786.3 kB ? eta -:--:--\n",
            "   --------------------------------- ----- 665.6/786.3 kB 13.9 MB/s eta 0:00:01\n",
            "   --------------------------------------- 786.3/786.3 kB 12.5 MB/s eta 0:00:00\n",
            "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
            "   ---------------------------------------- 0.0/107.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 107.2/107.2 kB 6.5 MB/s eta 0:00:00\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 73.5/73.5 kB 2.0 MB/s eta 0:00:00\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "   ---------------------------------------- 0.0/78.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 78.8/78.8 kB 4.3 MB/s eta 0:00:00\n",
            "Downloading jiter-0.10.0-cp311-cp311-win_amd64.whl (209 kB)\n",
            "   ---------------------------------------- 0.0/209.2 kB ? eta -:--:--\n",
            "   --------------------------------------- 209.2/209.2 kB 12.4 MB/s eta 0:00:00\n",
            "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "   ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 444.8/444.8 kB 9.2 MB/s eta 0:00:00\n",
            "Downloading pydantic_core-2.33.2-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
            "   ----------------- ---------------------- 0.9/2.0 MB 27.7 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.7/2.0 MB 21.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.9/2.0 MB 17.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.0/2.0 MB 15.5 MB/s eta 0:00:00\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 70.4/70.4 kB 4.0 MB/s eta 0:00:00\n",
            "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "   ---------------------------------------- 0.0/161.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 161.2/161.2 kB 4.7 MB/s eta 0:00:00\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.10.0 certifi-2025.8.3 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.99.6 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\simen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.4.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.11.7)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading sqlalchemy-2.0.42-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
            "  Downloading orjson-3.11.1-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
            "     ---------------------------------------- 0.0/43.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 43.2/43.2 kB 1.0 MB/s eta 0:00:00\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
            "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
            "  Downloading charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl.metadata (37 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
            "   ---------------------- ----------------- 0.6/1.0 MB 18.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.0/1.0 MB 12.9 MB/s eta 0:00:00\n",
            "Downloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
            "   ---------------------------------------- 0.0/443.5 kB ? eta -:--:--\n",
            "   --------------------------------------  440.3/443.5 kB 26.9 MB/s eta 0:00:01\n",
            "   --------------------------------------  440.3/443.5 kB 26.9 MB/s eta 0:00:01\n",
            "   --------------------------------------  440.3/443.5 kB 26.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 443.5/443.5 kB 2.8 MB/s eta 0:00:00\n",
            "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
            "Downloading langsmith-0.4.13-py3-none-any.whl (372 kB)\n",
            "   ---------------------------------------- 0.0/372.7 kB ? eta -:--:--\n",
            "   --------------------------------------- 372.7/372.7 kB 11.3 MB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
            "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 162.0/162.0 kB 9.5 MB/s eta 0:00:00\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "   ---------------------------------------- 0.0/64.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 64.8/64.8 kB 3.4 MB/s eta 0:00:00\n",
            "Downloading sqlalchemy-2.0.42-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 0.8/2.1 MB 25.6 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 1.6/2.1 MB 20.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.1/2.1 MB 19.2 MB/s eta 0:00:00\n",
            "Downloading charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl (107 kB)\n",
            "   ---------------------------------------- 0.0/107.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 107.1/107.1 kB 6.1 MB/s eta 0:00:00\n",
            "Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
            "   ---------------------------------------- 0.0/299.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 299.1/299.1 kB 9.0 MB/s eta 0:00:00\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.11.1-cp311-cp311-win_amd64.whl (131 kB)\n",
            "   ---------------------------------------- 0.0/131.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 131.4/131.4 kB 7.6 MB/s eta 0:00:00\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 54.5/54.5 kB 2.8 MB/s eta 0:00:00\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "   ---------------------------------------- 0.0/129.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 129.8/129.8 kB 8.0 MB/s eta 0:00:00\n",
            "Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
            "   ---------------------------------------- 0.0/495.4 kB ? eta -:--:--\n",
            "   --------------------------------------- 495.4/495.4 kB 10.3 MB/s eta 0:00:00\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: zstandard, urllib3, tenacity, PyYAML, orjson, jsonpointer, greenlet, charset_normalizer, SQLAlchemy, requests, jsonpatch, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.42 charset_normalizer-3.4.3 greenlet-3.2.4 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langsmith-0.4.13 orjson-3.11.1 requests-2.32.4 requests-toolbelt-1.0.0 tenacity-9.1.2 urllib3-2.5.0 zstandard-0.23.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\simen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.3.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
            "     ------ --------------------------------- 10.2/60.9 kB ? eta -:--:--\n",
            "     ------------ ------------------------- 20.5/60.9 kB 165.2 kB/s eta 0:00:01\n",
            "     ------------------------- ------------ 41.0/60.9 kB 281.8 kB/s eta 0:00:01\n",
            "     -------------------------------------- 60.9/60.9 kB 325.0 kB/s eta 0:00:00\n",
            "Downloading numpy-2.3.2-cp311-cp311-win_amd64.whl (13.1 MB)\n",
            "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/13.1 MB 5.9 MB/s eta 0:00:03\n",
            "   -- ------------------------------------- 0.7/13.1 MB 7.4 MB/s eta 0:00:02\n",
            "   --- ------------------------------------ 1.2/13.1 MB 9.2 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 1.7/13.1 MB 9.9 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 2.3/13.1 MB 11.5 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 3.1/13.1 MB 13.1 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 3.9/13.1 MB 13.8 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 4.6/13.1 MB 14.8 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 5.4/13.1 MB 15.0 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 6.2/13.1 MB 15.8 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 7.0/13.1 MB 15.9 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 7.7/13.1 MB 16.5 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 8.5/13.1 MB 16.4 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 9.3/13.1 MB 16.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 10.0/13.1 MB 16.9 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 10.8/13.1 MB 18.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.6/13.1 MB 19.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 12.3/13.1 MB 19.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  13.1/13.1 MB 19.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 13.1/13.1 MB 18.7 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-2.3.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\simen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\simen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install openai\n",
        "%pip install langchain\n",
        "%pip install numpy\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Laq8ql09DtyE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SUCCESS] API Key is configured correctly.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Once you add your API key below, make sure to not share it with anyone! The API key should remain private.\n",
        "OPENAI_API_KEY: str = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# There are many different models to try out \"gpt-4\", \"gpt-4-turbo-preview\", \"gpt-3.5-turbo\"\n",
        "MODEL_NAME: str = \"gpt-4o\"\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "  print(\"[ERROR] The key is not configured correctly\")\n",
        "else:\n",
        "  print(\"[SUCCESS] API Key is configured correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AJ7gr0Q81D-a"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=OPENAI_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrJPFSSqDWgw"
      },
      "source": [
        "## Part 1: API Connections (10 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Mj506eumJEMT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Answer for the language model \n",
            "ChatCompletion(id='chatcmpl-CZDnDsnT7akHZZcwWUyV2sFHDSNP6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In the realm of the digital sea,  \\nLarge Language Models roam free.  \\nWith words they entwine,  \\nThought and design,  \\nCrafting tales from just you and me.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1762510535, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_cbf1785567', usage=CompletionUsage(completion_tokens=37, prompt_tokens=36, total_tokens=73, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
            "\n",
            "The answer of the model: \n",
            "In the realm of the digital sea,  \n",
            "Large Language Models roam free.  \n",
            "With words they entwine,  \n",
            "Thought and design,  \n",
            "Crafting tales from just you and me.\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex AI concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Create a limerick about Large Language Models\"}\n",
        "  ]\n",
        ")\n",
        "print(\"The Answer for the language model \")\n",
        "print(completion)\n",
        "print(\"\\nThe answer of the model: \")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnVvFY5KTBzL"
      },
      "source": [
        "## Part 2: Understanding Completion Parameters (15 min)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXb8iu43y2Bu"
      },
      "source": [
        "### Key Parameters:\n",
        "* **Model Name:** Specifies the particular model version you want to use (e.g., text-davinci-003). Different models have varying capabilities, sizes, and costs.\n",
        "\n",
        "* **Messages:** The list of input text that you provide to the model. This is where the art of prompt engineering comes into play, guiding the model to generate the desired output.\n",
        "\n",
        "* **Temperature:** Controls the randomness of the output. A higher temperature leads to more varied responses, while a lower temperature results in more deterministic outputs. It's typically set between 0 and 2.\n",
        "\n",
        "* **Max Tokens:** Determines the maximum length of the model's response, measured in tokens (words or pieces of words). This helps control output verbosity.\n",
        "\n",
        "* **Top P:** Influences sample diversity by only considering the top P percent of probability mass when generating responses. Adjusting this can affect the creativity and relevance of the output.\n",
        "\n",
        "* **Frequency Penalty:** Discourages repetition by penalizing words based on their frequency in the text so far. This can help generate more diverse and interesting responses.\n",
        "\n",
        "* **Presence Penalty:** Similar to frequency penalty but penalizes based on the presence of words, encouraging the model to introduce new concepts and terms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb3V46jsfYZW"
      },
      "source": [
        "\n",
        "### **Task 2.1** Experimenting with Parameters\n",
        "Now that you're familiar with the parameters that can influence the behavior of LLMs, let's put this knowledge to the test. Your task is to experiment with these parameters to see firsthand how they affect the model's outputs.\n",
        "\n",
        "**Choose a Prompt:** *Start with a simple prompt, such as asking the model to write a short story about a space adventure.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3_U5DyXgkrUr"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in your own prompt\n",
        "prompt: str = \"Write a paragraph about a fantasy adventure\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DQV5OFkq7h"
      },
      "source": [
        "### **Task 2.2**\n",
        "*Vary the Temperature: Generate three completions using temperatures of 0.0, 1.0, and 2.0. Observe how the creativity and variability of the responses change.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I1EY_E3ofc7U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Model responded with: 'In the heart of the mystical realm of Eldoria, where the skies shimmered with hues of lavender and gold, a band of unlikely heroes embarked on a quest that would alter the fate of their world. Led by Elara, a fierce and wise elven sorceress, the group included Thorne, a brooding warrior with a mysterious past, and Lira, a nimble thief with a heart of gold. Their journey began in the ancient city of Luminastra, where they discovered a hidden map leading to the fabled Crystal of Aetheria, a powerful artifact said to hold the essence of magic itself. As they traversed through enchanted forests, scaled treacherous mountains, and navigated the labyrinthine caves of the Shadowlands, they faced formidable foes and forged unbreakable bonds. With each step, the air crackled with anticipation, for they knew that the destiny of Eldoria rested upon their shoulders, and the balance between light and darkness hung by a thread.'\n"
          ]
        }
      ],
      "source": [
        "# TODO: Change the temperature\n",
        "TEMPERATURE: float = 0.0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  temperature=TEMPERATURE,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{output}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfXf7CeYi27x"
      },
      "source": [
        "\n",
        "### **Task 2.3**\n",
        "*Adjust Max Tokens: Try generating responses with different limits on length, such as 50, 100, and 2000 tokens, to see how it impacts the detail and depth of the story.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lQPLKOVDjecx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Model responded with: 'In the heart of the ancient, mist-covered Forest of Eldergrove, a band of unlikely companions set forth on an epic quest to recover the lost Amulet of Lyria, a mystical artifact said to bestow unimaginable power upon its bearer. Led by Elara, the fierce and enigmatic elf with sapphire eyes and arrows that never missed their mark, the group ventured into territories few dared to traverse. Among them was Brom, a hulking warrior whose strength was rivaled only by his steadfast loyalty; Lyra, a cunning rogue with a silver tongue and a past shrouded in mystery; and Thrain, a wise and gentle dwarf whose knowledge of the arcane was as vast as the caverns beneath his mountain home. Their journey took them through treacherous landscapes, from the icy peaks of the Frostvale Mountains to the fiery depths of the Fireforged Caverns, facing challenges and creatures that tested their courage and camaraderie. As they uncovered clues to the Amulet's whereabouts,'\n"
          ]
        }
      ],
      "source": [
        "# TODO: Change the MAX_TOKENS\n",
        "MAX_TOKENS: int = 200\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  max_tokens=MAX_TOKENS,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{output}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM0XCIVhje2V"
      },
      "source": [
        "\n",
        "### **Task 2.4**\n",
        "*Experiment with Top P, Frequency Penalty, and Presence Penalty: Adjust these parameters to explore their effects on repetition, novelty, and thematic diversity.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yMhkJ1u2jg5k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Model responded with: 'In the heart of Eldoria, a realm where magic weaves through every breath and shadow, young Elara embarked on an epic quest that would test her courage beyond measure. Armed with only an ancient map whispered to hold secrets of forgotten realms, she ventured into the Enchanted Forest—a place teeming with mystical creatures and hidden dangers. Her journey was guided by whispers from ethereal spirits who spoke in riddles about a lost artifact capable of restoring balance to their world. Alongside companions as diverse as they were loyal—an enigmatic elven archer named Thalion and Brumbletusk, a jovial dwarf warrior whose laughter could shake mountains—they faced trials crafted by time itself: rivers flowing backward under moonlit skies and labyrinthine caves echoing tales long past. As destiny intertwined their fates beneath starlit canopies painted across twilight horizons, Elara discovered not just the power within herself but also forged bonds unbreakable even amidst chaos's stormy embrace; together they illuminated paths toward hope’s dawn for all beings dwelling in this wondrous land suspended between dreams' tapestry threads.\n",
            "'\n"
          ]
        }
      ],
      "source": [
        "# TODO: Change the different parameters and check effect on output\n",
        "# TOP_P can be any float number between 0 and 1\n",
        "TOP_P: float = 0\n",
        "# FREQUENCY_PENALTY can be any float Number between -2.0 and 2.0.\n",
        "FREQUENCY_PENALTY: float = 2.0\n",
        "# PRESENCE_PENALTY  can be any float Number between -2.0 and 2.0.\n",
        "PRESENCE_PENALTY: float = 2.0\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=MODEL_NAME,\n",
        "  top_p=TOP_P,\n",
        "  frequency_penalty=FREQUENCY_PENALTY,\n",
        "  presence_penalty=PRESENCE_PENALTY,\n",
        "\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        ")\n",
        "output = completion.choices[0].message.content\n",
        "print(f\"The Model responded with: '{output}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fKfM7-gjgbk"
      },
      "source": [
        "\n",
        "Reflect on how each parameter influenced the model's output. This exercise will enhance your understanding of how to control and guide the AI to achieve results that best fit your objectives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwGSpodOb4LR"
      },
      "source": [
        "## Part 3: Prompt engineering (15 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUeHYM4lS4jh"
      },
      "source": [
        "\n",
        "Prompt engineering is an art and science of designing inputs that guide Large Language Models (LLMs), such as Generative Pre-trained Transformer (GPT), to produce specific, high-quality responses or outputs. This process is foundational in the field of artificial intelligence because the precision with which we articulate our prompts significantly affects the AI's performance. A well-crafted prompt can lead to outputs that are not only accurate but also creative and contextually relevant, showcasing the model's capabilities to their fullest extent.\n",
        "\n",
        "### Engaging with Prompt Engineering\n",
        "Before we dive into specific tactics for effective prompt engineering, it's important to understand that the goal is to communicate with the model in its language. This means being clear, direct, and detailed in your requests.\n",
        "\n",
        "#### Tactics:\n",
        "<ul> \n",
        "    <li> <b>Include details in your query</b> to get more relevant answers.  \n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Often people ask questions that are too broad or vague. Remember, the AI can't read your mind ;) \n",
        "            <br>\n",
        "            Your goal is to extract specific information from the AI.\n",
        "            <p> <i>Bad:</i> \"Tell me about dogs.\"</p>\n",
        "            <p> <i>Good:</i> \"Provide a detailed comparison between the adaptability, exercise needs, and temperament of Labrador Retrievers and Border Collies for potential dog owners.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Ask the model to adopt a persona</b> for more tailored responses. \n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to make the interaction more engaging or specific.\n",
        "            <p> <i>Bad:</i> \"Explain quantum physics.\"</p>\n",
        "            <p> <i>Good:</i> \"Pretend you're a renowned physicist explaining the concepts of quantum physics to a high school student in a way that's easy to understand.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Use delimiters</b> to clearly indicate distinct parts of the input.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to organize a multi-part question.\n",
        "            <p> <i>Bad:</i> \"What is the capital of France and tell me about its history.\"</p>\n",
        "            <p> <i>Good:</i> \"Question 1: What is the capital of France? | Question 2: Provide a brief history of the capital.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Specify the steps</b> required to complete a task.\n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to get a walkthrough.\n",
        "            <p> <i>Bad:</i> \"How to bake a cake.\"</p>\n",
        "            <p> <i>Good:</i> \"List all the steps necessary to bake a chocolate cake, then create a list of needed ingredients with quantities, and baking time. Before estimating total time needed.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Provide examples</b> to illustrate the type of response you're seeking. \n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to clarify your expectations.\n",
        "            <p> <i>Bad:</i> \"Generate a catchy slogan for my product.\"</p>\n",
        "            <p> <i>Good:</i> \"Generate a catchy slogan for my eco-friendly water bottle product. For example, something like 'Hydrate Sustainably' or 'Drink Green, Live Clean'.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "    <li> <b>Specify the desired length</b> of the output to control verbosity. \n",
        "        <details>\n",
        "            <summary>Example</summary>\n",
        "            Your goal is to manage the depth of the response.\n",
        "            <p> <i>Bad:</i> \"Write an article on climate change.\"</p>\n",
        "            <p> <i>Good:</i> \"Write a concise 300-word article on the impacts of climate change on global weather patterns.\"</p>\n",
        "        </details>\n",
        "    </li>\n",
        "</ul>\n",
        "\n",
        "\n",
        "### Applying What We've Learned\n",
        "Now that we've outlined the key tactics for effective prompt engineering, let's put this knowledge into practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8-IT4a3YB6j"
      },
      "source": [
        "### **Task 3.1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSS-0U6sgp7v"
      },
      "source": [
        "Imagine you're working on the Cogito Project **TutorAI**, a cutting-edge AI tool designed to support students in their study efforts by creating concise, informative flashcards from dense academic texts. Your challenge is to engineer a prompt that instructs the LLM to distill complex material into easy-to-review flashcards, focusing on key concepts, definitions, and examples relevant to an upcoming exam.\n",
        "\n",
        "* **Extract Key Concepts and Definitions:** The AI must identify and summarize the main ideas and definitions found in a given academic text. This involves discerning the most important points that are crucial for understanding the subject matter.\n",
        "\n",
        "* **Format the Information for Flashcards:** The output should be structured in a way that is suitable for flashcard creation. Each flashcard will have a term or concept on one side and its definition or explanation on the other side, along with an example if appropriate.\n",
        "\n",
        "* **Control the Length:** Each flashcard content (term/definition/example) should be concise, aiming for no more than 50 words per side to facilitate quick review and memorization.\n",
        "\n",
        "This task will test your ability to use detailed queries, specify a structure, and control the output length—all crucial aspects of prompt engineering. Remember, the effectiveness of your prompt will directly influence the quality and relevance of the AI's response. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "931QTomvYCpj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Model responded with the following flashcards: \n",
            "'**Flashcard 1:**  \n",
            "Q: What is the Turing Test?  \n",
            "A: A test to determine if a computer can act humanly, meaning a human interrogator cannot tell if they are communicating with a computer or a human.\n",
            "\n",
            "**Flashcard 2:**  \n",
            "Q: What capabilities does a computer need to pass the Turing Test?  \n",
            "A: Natural language processing, knowledge representation, automated reasoning, and machine learning.\n",
            "\n",
            "**Flashcard 3:**  \n",
            "Q: Define \"Acting Humanly\" in AI.  \n",
            "A: When a computer behaves indistinguishably from a human, typically measured by the Turing Test.\n",
            "\n",
            "**Flashcard 4:**  \n",
            "Q: Define \"Thinking Humanly\" in AI.  \n",
            "A: Creating a computer that mimics human thinking processes, verified by comparing its input-output with human behavior.\n",
            "\n",
            "**Flashcard 5:**  \n",
            "Q: Define \"Acting Rationally\" in AI.  \n",
            "A: An agent acts to achieve the best expected outcome, considering its knowledge and environment.\n",
            "\n",
            "**Flashcard 6:**  \n",
            "Q: Define \"Thinking Rationally\" in AI.  \n",
            "A: Using logical rules to reach correct conclusions, exemplified by the modus ponens logic rule.\n",
            "\n",
            "**Flashcard 7:**  \n",
            "Q: What is an example of thinking rationally?  \n",
            "A: \"Socrates is a man; all men are mortal; therefore, Socrates is mortal,\" demonstrating modus ponens.'\n"
          ]
        }
      ],
      "source": [
        "book_paragraphs: str = \"\"\"\n",
        "Chapter 1 - Epic Introduction\n",
        "Since the dawn of time, humans have tried to define how we think, and this struggle has led us to create artificial intelligence. Historically, four approaches to artificial intelligence have been followed, each described below.\n",
        "\n",
        "Acting Humanly\n",
        "If we can't distinguish between a computer and a human, the computer is said to act humanly. The computer's capability to act humanly can be tested by performing a turing test. A computer passes the turing test if a human interrogator cannot tell whether he is communicating with a computer or a person. To pass a turing test, the computer would need to possess the following capabilities:\n",
        "\n",
        "Natural language processing to enable it to communicate successfully.\n",
        "Knowledge representation to store what it knows or hears.\n",
        "Automated reasoning to use the stored information to draw conclusions.\n",
        "Machine learning to adapt to new circumstances and to detect patterns.\n",
        "\n",
        "Thinking humanly\n",
        "To make a computer think like a human, we must know how humans think. The computers ability to think humanly can be determined by comparing the computer's input-output mechanism by the corresponding human behaviour.\n",
        "\n",
        "Acting Rationally\n",
        "An agent is something that acts. A rational agent is an agent that does the right thing based on what it knows, its functions, and the surrounding environment; it acts so that it achieves the best expected outcome.\n",
        "\n",
        "Thinking rationally\n",
        "Using sound logic rules to reach the right conclusion.\n",
        "\n",
        "A relevant quote, demonstrating the logical rule of modus ponens: \"Socrates is a man; all men are mortal; therefore, Socrates is mortal.\n",
        "\"\"\"\n",
        "\n",
        "def generate_flashcards_from_paragraphs(paragraphs: str) -> str:\n",
        "  completion = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "      # TODO: Create a prompt or combination of \"system\" and \"user\" prompts to achieve tasks objectives\n",
        "      {\"role\": \"system\", \"content\":  \"You are TutorAI, an assistant that creates concise, informative flashcards from academic texts. Your goal is to identify key terms, definitions, and examples; then present them in a clear flashcard format. Keep each definition under 50 words.\"},\n",
        "      {\"role\": \"user\", \"content\": paragraphs},\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "flashcards = generate_flashcards_from_paragraphs(book_paragraphs)\n",
        "print(f\"The Model responded with the following flashcards: \\n'{flashcards}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbtcDwricare"
      },
      "source": [
        "## Part 4: Embeddings (15 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UdYuCgxLcdZW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.023320836946368217, 0.0036924658343195915, 0.0025099546182900667, 0.0012706232955679297, -0.010718362405896187, 0.007365168537944555, 0.00589938135817647, -0.014400946907699108, -0.008801310323178768, -0.036733612418174744, 0.01187122892588377, 0.03631199151277542, -0.013089972548186779, -0.0034981255885213614, 0.004015268292278051, 0.017484040930867195, 0.02378198318183422, 0.003939508926123381, 0.0070950682274997234, -0.020580310374498367, -0.01803741604089737, 0.01043508667498827, 0.005425059236586094, -0.012898926623165607, -0.007193885277956724, 0.006495577748864889, 0.014572229236364365, -0.018485387787222862, -0.0017704732017591596, -0.01963166519999504, 0.0022612647153437138, -0.0069040218368172646, -0.011647243052721024, -0.029671482741832733, -0.00385057320818305, -0.00227608741261065, -0.0015736623900011182, -0.02946067415177822, 0.01401885412633419, 0.003071565181016922, 0.013215141370892525, -0.007622092962265015, -0.0031769699417054653, -0.012958216480910778, -0.015902966260910034, 0.006897434126585722, 0.0018824659055098891, -0.013485241681337357, -0.003626587800681591, -0.003919745329767466, 0.03249106556177139, 0.01968436874449253, -0.02806405909359455, -0.00632100086659193, -0.01675938069820404, 0.009664312936365604, -0.012022747658193111, 0.006212302017956972, 0.005523876287043095, -0.020409027114510536, 0.006689918227493763, 0.018972884863615036, -0.02234584279358387, 0.0012714468175545335, -0.014545878395438194, -0.010046405717730522, 0.0035574159119278193, 0.011950282379984856, 0.008913302794098854, 0.006386878900229931, 0.0304093174636364, 0.012813284993171692, -0.009927825070917606, -0.006897434126585722, 0.013070209883153439, 0.0024111373350024223, -0.017128298059105873, -0.004664167296141386, 0.0091043496504426, 0.0003495655255392194, -0.0027767608407884836, -0.03220120072364807, 0.00838627852499485, 0.02496778964996338, 0.0021278616040945053, 0.0027108825743198395, -0.009881710633635521, 0.038420092314481735, -0.005988316610455513, 0.011449608951807022, 0.012793521396815777, 0.005836796946823597, -0.008926479145884514, -0.00041750227683223784, -0.0012376842787489295, 0.035389699041843414, -0.0020488081499934196, 0.021621182560920715, 0.027378926053643227, -0.005398707929998636, 0.0024786624126136303, 0.02388738840818405, -0.012207206338644028, -0.01654857210814953, -0.0332816019654274, -0.006805204786360264, 0.00630453135818243, -0.005461292341351509, 0.02372928149998188, 0.0033021382987499237, -0.009901474229991436, 0.015968844294548035, 0.0005978434928692877, -0.04461263120174408, 0.0036759963259100914, 0.01257612369954586, 0.0046048774383962154, -0.014480000361800194, -0.004716869909316301, -0.023070501163601875, 0.021739764139056206, 0.03868360444903374, -0.014875268563628197, -0.0027405277360230684, 0.02499414049088955, -0.00662733381614089, 0.0014550818596035242, -0.020277271047234535, -0.021911047399044037, -0.007984422147274017, 0.014387770555913448, 0.005042966455221176, 0.009460090659558773, 0.006712975446134806, -0.01928909868001938, 0.028406623750925064, -0.002852520439773798, 0.015428644604980946, -0.03193768858909607, -0.019855650141835213, 0.01816917210817337, 0.015758035704493523, -0.0166408009827137, -0.00028615788323804736, -0.0183404553681612, 0.024256305769085884, -0.004058089107275009, 0.013597234152257442, 0.0015934258699417114, -0.020105987787246704, 0.014335068874061108, -0.005579872522503138, -0.009249281138181686, 0.0055041126906871796, -0.0054876431822776794, 0.03214849904179573, 0.015059727244079113, -0.01687796227633953, -0.014677634462714195, -0.009473267011344433, -0.005635869223624468, 0.01323490496724844, -0.001701301196590066, 0.0003744756686501205, 0.018551265820860863, 0.024032320827245712, 0.009973940439522266, 0.006525223143398762, 0.0004965559928677976, -0.0026878253556787968, -0.002149272011592984, 0.014361419714987278, -0.032780930399894714, 0.0060574887320399284, -0.0182086993008852, -0.0010359326843172312, 0.01182511355727911, -0.008122766390442848, -0.027010008692741394, -0.027589736506342888, -0.016192829236388206, -0.007141183130443096, -0.0020553958602249622, 0.027537034824490547, -0.007918544113636017, -0.009552320465445518, 0.006103603169322014, -0.01531006395816803, 0.011996396817266941, -0.011100455187261105, 0.010112283751368523, 0.0366809107363224, 0.0007324818288907409, 0.011291501112282276, -0.688083291053772, -0.004614758770912886, 0.0416349396109581, -0.020066460594534874, 0.0077011464163661, 0.024414412677288055, 0.002552775200456381, -0.020237743854522705, -0.005481055472046137, 0.0210151057690382, -0.007055541500449181, -0.008662966080009937, -0.017036069184541702, -0.004479709081351757, 0.01264200173318386, 0.0008284167270176113, -0.0010696952231228352, -0.03193768858909607, 0.014532702974975109, 0.010250627994537354, -0.013248080387711525, 0.010823767632246017, 0.007167534437030554, -0.002323848893865943, 9.598641190677881e-05, 0.008630027063190937, 0.009552320465445518, -0.014703985303640366, 0.010323094204068184, 0.012213794514536858, -0.008162292651832104, 0.019882002845406532, 0.006189244799315929, 0.0030303914099931717, 0.04065994545817375, -0.023953266441822052, -0.015191483311355114, 0.020395850762724876, 0.007477161008864641, 0.02508636936545372, -0.02509954571723938, -0.006798617076128721, 0.01455905381590128, -0.01179876271635294, -0.00415690615773201, 0.024058671668171883, 0.0152705367654562, -0.0047300453297793865, -0.01400567777454853, -0.016008371487259865, -0.0009132347768172622, 0.02787959948182106, -0.011508898809552193, 0.010645896196365356, -0.0007226000889204443, -0.024177253246307373, 0.023426242172718048, 0.011851465329527855, 0.015362766571342945, -0.005569991189986467, -0.005708334967494011, 0.01466445904225111, -0.01336666103452444, 0.0021344495471566916, -0.007213648874312639, 0.01828775182366371, -0.03317619860172272, 0.04487614333629608, 0.013406187295913696, -0.030962694436311722, 0.020132338628172874, 0.00010983109677908942, 0.0026038307696580887, -0.008728844113647938, 0.003880218369886279, 0.031384311616420746, 0.013649936765432358, -0.016166478395462036, -0.007200473453849554, 0.00917681585997343, -0.005961965303868055, -0.009367861784994602, -0.0064165242947638035, -0.0015563694760203362, 0.008768371306359768, 0.005728098563849926, -0.03222755342721939, 0.00971042737364769, 0.014967498369514942, -0.003847279353067279, 0.014111083000898361, 0.010902821086347103, -0.02940797060728073, -0.02668061852455139, -0.0036759963259100914, 0.02227996475994587, 0.013465478084981441, 0.011732884682714939, 0.029724186286330223, -0.0010935759637504816, -0.008300636895000935, -0.009077997878193855, 0.015428644604980946, 0.013518180698156357, 0.015876615419983864, 0.005761037580668926, -0.015534048900008202, 0.018946534022688866, -0.003939508926123381, -0.036786314100027084, -0.02220091037452221, -0.009381037205457687, -0.011166333220899105, -0.004986970219761133, -0.01803741604089737, -0.02772149257361889, 0.017444513738155365, 0.015863439068198204, 0.02370293065905571, -0.0014064968563616276, 0.004538998939096928, 0.006722857244312763, 0.0026927662547677755, 0.01316902693361044, -0.0021805642172694206, 0.009275632910430431, 0.006719563156366348, -0.02242489531636238, -0.02354482375085354, 0.02238536812365055, 0.012846224009990692, 0.003965859767049551, 0.012497070245444775, -0.007338817231357098, 0.02641710638999939, -0.000363976345397532, 0.002915104618296027, 0.003610118292272091, 0.008906715549528599, -0.03075188398361206, 0.01193051878362894, 0.019210046157240868, 0.004235960077494383, -0.03062012791633606, -0.024625223129987717, -0.003008981002494693, -0.02226678840816021, 0.003079799935221672, -0.009901474229991436, -0.012055687606334686, 0.010375795885920525, 0.0029694540426135063, 0.007826315239071846, 0.0091372886672616, 0.006706387735903263, -0.004374303855001926, -0.014361419714987278, -0.015151956118643284, -0.007358580827713013, -0.025942783802747726, -0.004021856468170881, 0.031305260956287384, -0.020514432340860367, -0.011581365019083023, -0.01824822649359703, -0.007351992651820183, 0.006212302017956972, 0.016996541991829872, -0.004084440413862467, -0.021792465820908546, 0.018722547218203545, -0.01328760664910078, -0.0016741264844313264, 0.0024868971668183804, 0.0046048774383962154, 0.008162292651832104, -0.020066460594534874, -0.021502602845430374, -0.005909263156354427, -0.02213503234088421, -0.007826315239071846, -0.005784094799309969, -0.005145077593624592, 0.0021640947088599205, 0.0153364147990942, 0.008834249339997768, 0.007977834902703762, 0.01812964491546154, -0.00899894442409277, -0.012365314178168774, 0.019275924190878868, 0.026983657851815224, -0.02076476812362671, 0.011291501112282276, -0.0076023293659091, 0.001900582341477275, -0.019210046157240868, 0.012833048589527607, 0.01654857210814953, 0.009605023078620434, 0.023004623129963875, 0.0027915833052247763, 0.0007880664197728038, 0.012088626623153687, 0.003567297477275133, -0.029618781059980392, -0.013715814799070358, -0.01685161143541336, 0.02790595032274723, 0.004881564993411303, 0.015758035704493523, 0.006452756933867931, -0.014190136454999447, 0.009203166700899601, 0.012800109572708607, 0.028406623750925064, -0.010724949650466442, 0.003254376817494631, -0.016443166881799698, -0.03228025510907173, -0.022727934643626213, -0.0057149226777255535, 0.020461728796362877, 0.0035607097670435905, -0.015494522638618946, 0.008827661164104939, 0.00038744541234336793, 0.005494231358170509, 0.0076813832856714725, -0.04181940108537674, 0.004489590413868427, 0.022978272289037704, 0.0183404553681612, 0.02349212020635605, -0.0025198361836373806, -0.012279672548174858, 0.020145514979958534, 0.011778999119997025, 0.025376232340931892, 0.0011528662871569395, 0.011877816170454025, 0.02809040993452072, 0.0361538864672184, -0.017642147839069366, 0.02245124615728855, 0.017352284863591194, 0.035547807812690735, 0.012859399430453777, -0.0020158689003437757, 0.008781546726822853, -0.0035145950969308615, -0.00181988172698766, 0.005500819068402052, 0.007180709857493639, 0.028801893815398216, -0.011482547968626022, -0.0018561147153377533, 0.018972884863615036, 0.008919890969991684, 0.02922351285815239, -0.009532556869089603, 0.0006287238211371005, -0.010066169314086437, 0.0014830800937488675, 0.010197925381362438, -0.008267697878181934, -0.030198508873581886, -0.01926274783909321, -0.014651283621788025, 0.02511272020637989, -0.011429845355451107, -0.01534959115087986, -0.005886205937713385, -0.014862093143165112, -0.008781546726822853, 0.0019582256209105253, 0.022622529417276382, 0.016192829236388206, -0.004624640569090843, 0.013610409572720528, 0.0013826159993186593, -0.028880946338176727, 0.03228025510907173, 0.004153612535446882, -0.016416816040873528, -0.016113776713609695, -0.0475112646818161, 0.014717161655426025, -0.01180535089224577, 0.018498562276363373, 0.016416816040873528, 0.03064647875726223, 0.011021401733160019, -0.009881710633635521, 0.013702639378607273, 0.013715814799070358, 0.032965388149023056, -0.005803857930004597, -0.0013620291138067842, -0.010889645665884018, -0.00832698866724968, 0.008597088046371937, -0.0073256418108940125, -0.0010696952231228352, 0.023979617282748222, -0.0073783439584076405, 0.015863439068198204, -0.0053558871150016785, -0.028880946338176727, 0.0006488990038633347, 0.0027273520827293396, 0.011587953194975853, -0.013399600051343441, -0.020540783181786537, 0.02079111896455288, 0.02250394970178604, 0.0030007462482899427, 0.0090714106336236, 0.028643785044550896, -0.001142984488978982, 0.002361728809773922, -0.016179654747247696, -0.009196578525006771, 0.017549918964505196, 0.050726115703582764, 0.012569536454975605, -0.00527024595066905, 0.0029085169080644846, -0.018788425251841545, -0.021160036325454712, -0.04010656848549843, 0.022596178576350212, -0.02227996475994587, -0.0036035305820405483, -0.01691748946905136, -0.002890400355681777, 0.01959213800728321, 0.007180709857493639, 0.019170518964529037, 0.012404841370880604, 0.001670832629315555, -0.006060782819986343, 0.015231010504066944, -0.010645896196365356, -0.002620300278067589, -0.0012212147703394294, -0.007240000180900097, 0.009479854255914688, 0.0023502002004534006, -0.029961347579956055, 0.009400800801813602, 0.0014814331661909819, -0.004295250400900841, -0.02246442250907421, 0.012391665019094944, 0.013281019404530525, -0.010257216170430183, 0.005952083971351385, -0.010230864398181438, 0.011673593893647194, 0.0015514285769313574, 0.014466824941337109, 0.023360364139080048, 0.0057149226777255535, 0.0076813832856714725, 0.011739472858607769, 0.0013257962418720126, 0.0006579572218470275, 0.014400946907699108, -0.02097557857632637, -0.013024094514548779, 0.01039555948227644, -0.007457397878170013, 0.001387556898407638, 0.015718508511781693, 0.00767479557543993, -0.01812964491546154, -0.020158689469099045, 0.008485095575451851, -0.0012203912483528256, -0.00229255692102015, -0.016416816040873528, -0.002865696093067527, -0.05141124874353409, -0.021700236946344376, -0.026193121448159218, -0.0021048043854534626, -0.02378198318183422, -0.0090055325999856, -0.023360364139080048, -0.008742020465433598, -0.005425059236586094, 0.01326125580817461, -0.00414702482521534, 0.003669408615678549, -0.021673886105418205, -0.029908644035458565, -0.04044913500547409, 0.000630782509688288, 0.011910755187273026, 0.015771210193634033, -0.027062712237238884, -0.0010804004268720746, -0.003959272056818008, -0.0016230710316449404, -0.0073256418108940125, 0.0025840674061328173, -0.016350938007235527, -0.013610409572720528, 0.0018165878718718886, 0.0022678526584059, -0.0016609508311375976, -0.006693212315440178, -0.006459345109760761, 0.033044442534446716, 0.023360364139080048, 0.018762074410915375, -0.002766879042610526, -0.005629281047731638, -0.0069040218368172646, 0.006301237735897303, 0.031041746959090233, -0.008583912625908852, -0.01799788884818554, 0.003748462302610278, -0.029513375833630562, 0.004749808926135302, -0.0015242538647726178, 0.014545878395438194, -0.004041619598865509, 0.018735723569989204, 0.010922584682703018, -0.010020054876804352, 0.0014163785381242633, -0.00552058219909668, -0.00975654274225235, -0.011416669934988022, 0.0052998908795416355, 0.03075188398361206, -0.010066169314086437, 0.0023007916752249002, 0.005108844488859177, -0.027062712237238884, -0.0007213648641481996, -0.004255723208189011, -0.006393467076122761, 0.006136542186141014, 0.017602620646357536, -0.0077340854331851006, 0.021357670426368713, -0.006647097412496805, 0.005830209236592054, -0.013636760413646698, 0.0033993085380643606, -0.007747261319309473, 0.03175323083996773, -0.023004623129963875, -0.011851465329527855, -0.0023765515070408583, -0.014638107270002365, -0.03610118478536606, -0.002844285685569048, -0.00984877161681652, 0.005062730051577091, -0.017404986545443535, 0.004041619598865509, 0.007780200336128473, 0.0003347429446876049, -0.03170052915811539, -0.027115413919091225, -0.020343149080872536, 0.016021547839045525, -0.0032395541202276945, 5.419500666903332e-05, 0.0031308552715927362, 0.022648880258202553, -0.017299581319093704, -0.02948702499270439, -0.002378198318183422, -0.00971042737364769, -0.029855942353606224, 0.026930956169962883, 0.0330180898308754, 0.005118726287037134, 0.05146395042538643, -0.013663112185895443, 0.021304968744516373, 0.0036759963259100914, 0.004680636804550886, 0.010105696506798267, 0.013096560724079609, -0.009539145044982433, 0.00010350062802899629, 0.009077997878193855, 0.014677634462714195, 0.00839286670088768, -0.007832902483642101, 0.011060927994549274, 0.0037649318110197783, 0.021489426493644714, -0.025955960154533386, -0.000943703402299434, -0.012411428615450859, -0.013952975161373615, -0.014993849210441113, 0.0033762510865926743, -0.010922584682703018, 0.01662762463092804, -0.02521812543272972, -0.008682729676365852, -0.0073981075547635555, 0.0027273520827293396, 0.020633012056350708, 0.007971246726810932, 0.00967748835682869, -0.00034585988032631576, 0.01408473215997219, 0.011653831228613853, -8.347987022716552e-05, -0.010883057489991188, -0.0024358415976166725, -0.006103603169322014, 0.0022497361060231924, 0.02383468672633171, 0.010118871927261353, 0.03222755342721939, -0.013432539068162441, 0.01786613278090954, 0.018590791150927544, 0.007055541500449181, -0.011331028304994106, -0.017747553065419197, 0.01541546918451786, -0.01105434074997902, -0.016113776713609695, -0.05986999347805977, -0.06139836460351944, -0.028432976454496384, -0.0015193130820989609, 0.020646188408136368, -0.017721202224493027, 0.009394212625920773, 0.003004040103405714, -0.016034722328186035, -0.017563093453645706, 0.018656669184565544, 0.04577208310365677, 0.0004467356775421649, 0.01653539575636387, 0.01400567777454853, -0.0014789627166464925, -0.003613412147387862, 0.027299873530864716, -0.006709681823849678, 0.007299290504306555, 0.02943432331085205, 0.006199126597493887, -0.008221583440899849, -0.012404841370880604, -0.008676142431795597, -0.0072663514874875546, -0.0018165878718718886, -0.02249077335000038, 0.015507698059082031, 0.00492438580840826, -0.026008661836385727, 0.013096560724079609, -0.007753849029541016, -0.028643785044550896, -0.0021179800387471914, -0.030172156170010567, -0.012945041060447693, -0.018577616661787033, -0.0029678072314709425, -0.02816946431994438, 0.030172156170010567, -0.011561601422727108, 0.02354482375085354, -0.010560254566371441, -0.0003977388550993055, -0.015020200051367283, -0.0017325932858511806, 0.014440473169088364, -0.0016535395989194512, 0.020198216661810875, 0.02491508610546589, -0.0090384716168046, 0.005985022988170385, 0.017773903906345367, -0.013887097127735615, -0.0009766423609107733, 0.021581657230854034, -0.011739472858607769, 0.027563385665416718, -0.010909408330917358, -0.017391810193657875, 0.0066800364293158054, 0.013089972548186779, 0.0063374703750014305, -0.00977630540728569, 0.004295250400900841, -0.018775250762701035, -0.001917051849886775, -0.016456343233585358, 0.021357670426368713, -0.009420564398169518, -0.0026466515846550465, 0.0010787533828988671, -0.013768517412245274, 0.01544182002544403, 0.004354540724307299, -0.013834395445883274, -0.0028245223220437765, -0.027405278757214546, 0.0010301683796569705, -0.007062129210680723, 0.010876469314098358, 0.0335451140999794, -0.008926479145884514, -0.008774959482252598, -0.0015119017334654927, 0.041292376816272736, -0.014927971176803112, -0.001599190174601972, 0.025494813919067383, 0.01056684274226427, -0.012464131228625774, -0.006792029365897179, 0.01972389407455921, -0.02345259301364422, 0.00841921754181385, -0.004973794333636761, 0.008465331979095936, -0.006192538887262344, -0.0017638853751122952, 0.0005340241477824748, -0.005178016610443592, -0.006541692651808262, -0.009308571927249432, -0.004064676817506552, 0.013649936765432358, -0.01330078300088644, -0.011133394204080105, 0.0014863739488646388, 0.0007592447800561786, 0.0197107195854187, 0.019802948459982872, -0.016403639689087868, 0.0030863876454532146, -0.0008242993499152362, -0.012786934152245522, -0.003033685265108943, -0.03504713252186775, -0.004614758770912886, 0.015705332159996033, 0.015428644604980946, -0.0027487624902278185, -0.01811647042632103, -0.021924221888184547, -0.01668032817542553, -0.009433739818632603, 0.018867479637265205, -0.0035738854203373194, -0.008774959482252598, 0.009222930297255516, 0.009927825070917606, 0.010303330607712269, -0.011014813557267189, -0.026272175833582878, -0.016232356429100037, 0.005474467761814594, -0.005392120219767094, -0.027352575212717056, -0.0008247111109085381, -0.014453648589551449, 0.01323490496724844, 0.00831381231546402, -0.031041746959090233, -0.015731683000922203, 0.003270846325904131, -0.03639104589819908, -0.020237743854522705, -0.008023949339985847, -0.019882002845406532, 0.008537798188626766, 0.02635122835636139, 0.009413976222276688, 0.013610409572720528, 0.00524718826636672, 0.025455286726355553, -0.020264094695448875, 0.003593648783862591, 0.007147770840674639, -0.020013758912682533, -0.00036500568967312574, 0.02109415829181671, -0.0166408009827137, -0.0034091901034116745, -0.002682884456589818, 0.001903876313008368, 0.010751301422715187, 0.025876905769109726, -0.009407388977706432, -0.0047531030140817165, 0.002424312988296151, -0.00383410369977355, 0.011719709262251854, 0.01531006395816803, 0.017233703285455704, -0.013636760413646698, 0.008438981138169765, -0.00588291184976697, 0.015784386545419693, 0.0030023930594325066, 0.006498871836811304, 0.01816917210817337, 0.0022727935574948788, 0.012497070245444775, -0.017101947218179703, 0.005471173673868179, -0.010935760103166103, -0.0011915696086362004, 0.014822565950453281, -0.009288808330893517, -0.018617143854498863, 0.027247169986367226, 0.011627479456365108, -0.010342856869101524, -0.002728999126702547, 0.009084586054086685, -0.01685161143541336, -0.029697835445404053, -0.00013103560195304453, -0.02665426768362522, -0.01451952662318945, -0.03375592455267906, 0.01052731554955244, -0.023070501163601875, 0.007180709857493639, 0.015151956118643284, -0.0025363056920468807, -0.009341510944068432, 0.01694384030997753, 0.00025630687014199793, -0.03217485174536705, -0.0052438946440815926, -0.022003276273608208, 0.007892193272709846, -0.03784036263823509, -0.0032757872249931097, -0.002559363143518567, 0.009143875911831856, 0.001391674275510013, -0.00017642970487941056, -0.014638107270002365, -0.0011075751390308142, 0.01686478592455387, 0.020224567502737045, 0.0052801272831857204, 0.02365022711455822, 0.2162908911705017, -0.022780636325478554, -0.0006114308489486575, 0.019987406209111214, -0.0032774340361356735, 0.0007460691849701107, 5.033496563555673e-05, 0.003893394023180008, -0.018630318343639374, -0.009973940439522266, 0.014875268563628197, 0.00020792766008526087, -0.0023551410995423794, -0.003596942638978362, 0.003564003622159362, -0.024598872289061546, -0.005859854631125927, -0.01786613278090954, -0.02790595032274723, -0.015125605277717113, -0.005062730051577091, -0.0197765976190567, -0.0024704276584088802, -0.018696196377277374, 0.013649936765432358, 7.18482697266154e-05, 0.0033927205950021744, 9.593494178261608e-05, 0.010850118473172188, 0.033993083983659744, -0.0050923749804496765, 0.0002361317165195942, 0.017246879637241364, -0.0035014194436371326, -0.01179217454046011, -0.0037682256661355495, 0.015889791771769524, 0.00020360441703815013, 0.02785324864089489, 0.016021547839045525, 0.031489718705415726, -0.020158689469099045, 0.0035442402586340904, -0.0027191173285245895, 0.007898780517280102, 0.00245395814999938, -0.021660709753632545, -0.008623439818620682, -0.009901474229991436, 0.03512618690729141, 0.006604276597499847, -0.0045225294306874275, 0.015231010504066944, 0.018603967502713203, -0.008221583440899849, -0.005569991189986467, -0.0005150841898284853, 0.017497215420007706, 0.024467116221785545, -0.006106897257268429, 0.014480000361800194, 0.027484331279993057, 0.0026779435575008392, 0.005836796946823597, -0.010356033220887184, 0.020369499921798706, -0.031226206570863724, 0.021278617903590202, 0.0016222475096583366, -0.01108069159090519, 0.0034454232081770897, -0.009301983751356602, -0.00244572339579463, -0.005029790569096804, -0.02927621454000473, -0.022662056609988213, 0.03620658814907074, 0.01930227503180504, 0.028854595497250557, 0.016390465199947357, -0.006498871836811304, -0.010099108330905437, -0.010342856869101524, -0.012958216480910778, -0.042741693556308746, -0.049619365483522415, 0.021845169365406036, -0.022767461836338043, 0.004324895329773426, -0.024005969986319542, 0.007892193272709846, 0.0008942948188632727, -0.0017194176325574517, -0.011093867011368275, 0.008030536584556103, 0.011014813557267189, 0.00527024595066905, 0.020119162276387215, -0.010580018162727356, 0.004305132199078798, -0.019763421267271042, 0.015099254436790943, 0.027247169986367226, -0.004795923829078674, -0.014282366260886192, 0.013689463026821613, -0.011653831228613853, -0.01117950864136219, 0.00623865332454443, -0.011390318162739277, -0.01967119239270687, -0.025850554928183556, 0.00209821667522192, -0.0168384350836277, -0.007971246726810932, 0.012885751202702522, 0.025389408692717552, -0.015020200051367283, 0.018406333401799202, -0.02085699699819088, -0.027537034824490547, -0.020303621888160706, -0.000277099636150524, 0.01322831679135561, -0.0026170064229518175, -0.008702493272721767, -0.012925277464091778, 0.007872429676353931, -0.012286260724067688, -0.01258271187543869, 0.02806405909359455, 0.002911810763180256, 0.021963749080896378, 0.01114656962454319, -0.017036069184541702, 0.038130227476358414, 0.01112021878361702, 0.019144168123602867, -0.010132047347724438, 0.02654886245727539, 0.01040214765816927, -0.023083675652742386, 0.00666027283295989, -0.008518034592270851, -0.010421911254525185, -0.028248516842722893, 0.013472065329551697, 0.006011373829096556, 0.0002416901697870344, -0.031384311616420746, -0.02533670701086521, -0.008992357179522514, -0.008603676222264767, -0.008985769003629684, 0.027537034824490547, -0.018419509753584862, 0.0015983667690306902, -0.04848626255989075, -0.020540783181786537, 0.008023949339985847, -0.02927621454000473, -0.0012887397315353155, 0.008116178214550018, -0.035653211176395416, -0.014901619404554367, -0.0064922841265797615, -0.17022894322872162, 0.009572084061801434, 0.0027734667528420687, -0.028116760775446892, -0.003435541409999132, 0.015929317101836205, 0.004417124669998884, 0.003942802548408508, -0.013794868253171444, -0.0020455140620470047, 0.019210046157240868, -0.010883057489991188, -0.031068097800016403, -0.012793521396815777, -0.006502165459096432, 0.01802423968911171, -0.010711774230003357, -0.022912394255399704, 0.0422937236726284, 0.010738126002252102, 0.030356615781784058, -0.035468753427267075, 0.014190136454999447, -0.006950136739760637, 0.0005105550517328084, 0.006070664152503014, -0.0013694404624402523, 0.032675523310899734, -0.004305132199078798, -0.0004599113017320633, 0.010731537826359272, -0.028222166001796722, 0.03454646095633507, -0.005003439728170633, 0.012800109572708607, 0.015007024630904198, 0.02361070178449154, -0.021924221888184547, -0.004894740879535675, 0.015916142612695694, 0.026035014539957047, -0.0026565331500023603, -0.017220528796315193, 0.006432993803173304, 0.0030073339585214853, 0.013024094514548779, 0.022569827735424042, -0.008103002794086933, 0.027457980439066887, -0.001299444935284555, 0.005632575135678053, -0.01928909868001938, 0.011456197127699852, 0.0014526115264743567, 0.009960764087736607, 0.019025586545467377, 0.007747261319309473, 0.018907006829977036, 0.014572229236364365, -0.005461292341351509, 0.02527082897722721, -0.03470456972718239, -0.01108727976679802, -0.027247169986367226, -0.02097557857632637, -0.028432976454496384, -0.020237743854522705, 0.006656979210674763, -0.002009281190112233, 0.005187897942960262, -0.016206005588173866, 0.002865696093067527, 0.006528516765683889, -0.007253175601363182, -0.00484203826636076, 0.027668790891766548, -0.013636760413646698, 0.022806989029049873, 0.0036035305820405483, -0.013623584993183613, -0.0018050591461360455, 0.029592430219054222, -0.0022069152910262346, 0.0036200000904500484, 0.0032741401810199022, -0.019130991771817207, 0.0010968699352815747, -0.0020043402910232544, -0.022938745096325874, -0.012253321707248688, 0.013063621707260609, -0.05004098266363144, -0.0023419654462486506, -0.016219181939959526, 0.012865987606346607, 0.02648298442363739, 0.0013949681306257844, -0.0012261556694284081, -0.0021937398705631495, -0.014638107270002365, -0.020145514979958534, -0.005988316610455513, -0.010757888667285442, 0.020000582560896873, 0.031173503026366234, 0.003058389527723193, 0.007516688201576471, -0.005059435963630676, 0.055337581783533096, -0.003613412147387862, -0.010757888667285442, -0.00844556838274002, 0.018472211435437202, 0.01531006395816803, 0.011673593893647194, 0.034151192754507065, -0.009348098188638687, -0.015955669805407524, 0.015837088227272034, 0.003643057309091091, 0.056655142456293106, 0.013821219094097614, -0.023979617282748222, 0.021252265200018883, -0.004855213686823845, -0.02495461329817772, -0.10034547746181488, -0.016061073169112206, 0.0182745773345232, 0.012418016791343689, -0.01316243875771761, 0.022069154307246208, 0.001007111044600606, 0.001268976368010044, -0.025718798860907555, 0.022951919585466385, -0.007964658550918102, -0.04851261153817177, -0.014651283621788025, -0.0090384716168046, -0.004937561694532633, 0.0045225294306874275, 0.011752648279070854, 0.010744713246822357, -0.017391810193657875, 0.03064647875726223, 0.0011075751390308142, -0.0027915833052247763, 0.024085022509098053, -0.015481347218155861, -0.000567374867387116, 0.013887097127735615, -0.022069154307246208, -0.0036331757437437773, 0.011508898809552193, -0.005708334967494011, 0.008188644424080849, -0.027484331279993057, -0.00025918905157595873, -0.020540783181786537, 0.003880218369886279, -0.0073190536350011826, -0.0018412921344861388, 0.003685878124088049, 0.022846516221761703, -0.042530883103609085, 0.004548880737274885, -0.02911810763180256, -0.015823913738131523, -0.015599927864968777, -0.0005381415248848498, 0.017444513738155365, -0.007213648874312639, 0.0004763808101415634, 0.02242489531636238, -0.015599927864968777, -0.026759672909975052, -0.012872574850916862, -0.024691101163625717, -0.0016881255432963371, 0.03056742623448372, 0.011396906338632107, 0.0042623113840818405, -0.01192393060773611, -0.010698598809540272, 0.0038604550063610077, -0.027247169986367226, -0.005784094799309969, -0.026957307010889053, 0.009157052263617516, 0.010013466700911522, -0.004341364838182926, -0.019987406209111214, -0.014901619404554367, -0.003288962645456195, -0.002277734223753214, -0.016140127554535866, 0.012062274850904942, -0.01387392170727253, 0.027405278757214546, -0.03322890028357506, 0.0022349136415868998, -0.016087425872683525, -0.015929317101836205, 0.020474905148148537, -0.009572084061801434, -0.021752938628196716, -0.014466824941337109, 0.017194176092743874, -0.019816124811768532, -0.002589008305221796, 0.021897871047258377, -0.010151810944080353, 0.013465478084981441, -0.008399453945457935, -0.03712888062000275, -0.012411428615450859, 0.010935760103166103, 0.02635122835636139, -0.031305260956287384, -0.012213794514536858, 0.009222930297255516, -0.012885751202702522, -0.004789335653185844, 0.02524447627365589, 0.01400567777454853, -0.024348534643650055, 0.0013150910381227732, -0.05438893660902977, 0.004249135497957468, -0.003992211073637009, -0.021555304527282715, -0.0018231755821034312, -0.024612046778202057, -0.019961055368185043, -0.0021953866817057133, 0.0016658917302265763, 0.019974231719970703, 0.0038143403362482786, 0.002500072820112109, 0.0028031119145452976, 0.010665659792721272, -0.015929317101836205, -0.023465769365429878, 0.021911047399044037, -0.0030386261641979218, 0.004565350245684385, 0.025824204087257385, -0.009585259482264519, -0.009993703104555607, 0.004799217451363802, 0.01818234845995903, 0.004509354010224342, -5.5327287554973736e-05, -0.014374595135450363, 0.01391344889998436, -0.021397197619080544, -0.009493030607700348, 0.0012286260025575757, -0.04181940108537674, -0.008656378835439682, 0.028564732521772385, 0.0008226524223573506, -0.022662056609988213, 0.024124549701809883, 0.015560400672256947, 0.03325524926185608, 0.01948673278093338, -0.012740818783640862, -0.024809682741761208, 0.020356323570013046, 0.009334922768175602, -0.005052848253399134, 0.012404841370880604, -0.013215141370892525, -0.002597243059426546, 0.015099254436790943, 0.007911956869065762, 0.022622529417276382, 0.01111363060772419, -0.011291501112282276, 0.009269044734537601, -0.0056391628459095955, 0.0017490627942606807, 0.026166770607233047, -0.002137743402272463, -0.0021179800387471914, -0.027326224371790886, 0.049619365483522415, 0.016298234462738037, 0.009018708020448685, -0.005178016610443592, 0.008814485743641853, 0.010066169314086437, -0.01693066395819187, 0.011060927994549274, 0.011383730918169022, -0.0009000591817311943, -0.01802423968911171, 0.012523421086370945, 0.005569991189986467, 0.00211468618363142, 0.008821073919534683, 0.004104204010218382, 0.015151956118643284, -0.0016066015232354403, -0.02237219363451004, 0.03320254758000374, 0.007516688201576471, -0.011205860413610935, -0.009532556869089603, 0.008913302794098854, 0.013346897438168526, 0.026193121448159218, 0.0008119472186081111, 0.011568189598619938, -0.005240600556135178, -0.0013760281726717949, -0.015086078085005283, -0.0015168426325544715, 0.013531356118619442, -0.002831110032275319, -0.013346897438168526, 0.0042392536997795105, 0.006017962004989386, 0.027616087347269058, 0.029934996739029884, 0.025705624371767044, 0.03649645298719406, 0.0036463511642068624, -0.017233703285455704, -0.04295250400900841, -0.020105987787246704, 0.017826605588197708, 0.004361128434538841, -0.03246471285820007, -0.00040041515603661537, 0.009631373919546604, 0.010085932910442352, 0.0005299067124724388, -0.03333430364727974, 0.004700400400906801, -0.020435377955436707, -0.013623584993183613, -0.009730190970003605, -0.017115123569965363, -0.03172687813639641, 0.021950572729110718, -0.007240000180900097, 0.0308045856654644, 0.01254318468272686, 0.01387392170727253, 0.018775250762701035, -0.004114085808396339, -0.011416669934988022, -0.012141328305006027, 0.013860746286809444, -0.004565350245684385, -0.004417124669998884, 0.005138489417731762, -0.008834249339997768, 0.0022036214359104633, -0.021990099921822548, 0.021397197619080544, -0.017642147839069366, 0.015086078085005283, 0.006936960853636265, 0.0673537403345108, -0.007272939197719097, -0.014651283621788025, 0.021225914359092712, -0.022662056609988213, 0.018459035083651543, 0.018406333401799202, 0.003613412147387862, -0.038472793996334076, -0.01811647042632103, 0.008465331979095936, -0.00012033041275572032, -0.006551574449986219, -0.026100892573595047, -0.012497070245444775, -0.0038571611512452364, 0.009796069003641605, 0.002957925433292985, -0.01949990913271904, 0.0167066790163517, 0.02065936289727688, 0.02362387627363205, 0.017365459352731705, 0.008768371306359768, -0.01660127379000187, 0.008511446416378021, 0.029908644035458565, -0.019249573349952698, -0.021239090710878372, -0.01189757976680994, 0.007885605096817017, -0.01197004597634077, -0.05149029940366745, -0.014440473169088364, 0.010052993893623352, -0.012727643363177776, -0.007108244113624096, -0.010211100801825523, 0.0076023293659091, 0.030093103647232056, 0.020540783181786537, 0.041292376816272736, -0.024730628356337547, -0.008050300180912018, 0.03320254758000374, 0.008471920154988766, -0.008597088046371937, -0.017207352444529533, -0.03346605971455574]\n"
          ]
        }
      ],
      "source": [
        "def create_embedding(prompt: str, model=\"text-embedding-ada-002\") -> list[float]:\n",
        "    return client.embeddings.create(model=model, input=prompt).data[0].embedding\n",
        "\n",
        "print(create_embedding(\"This is an embedding!\"))\n",
        "\n",
        "database: list[list[list[float]], str] = []\n",
        "\n",
        "# Create embedding-text key-value pairs and add them to the database\n",
        "corresponding_text_1 = \"This is an embedding!\"\n",
        "embedding_1 = create_embedding(corresponding_text_1)\n",
        "database.append([embedding_1, corresponding_text_1])\n",
        "\n",
        "corresponding_text_2 = \"Sverre is CTO of Cogito NTNU\"\n",
        "embedding_2 = create_embedding(corresponding_text_2)\n",
        "database.append([embedding_2, corresponding_text_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dfi_Eg6FUB7D"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(np.float64(0.8882484053164321), 'Sverre is CTO of Cogito NTNU')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a: list[float], b: list[float]) -> float:\n",
        "    \"\"\" \n",
        "    Takes 2 vectors a, b and finds how similar they are using the cosine similarity \n",
        "\n",
        "    Args:\n",
        "    a (list[float]): A list of floats\n",
        "    b (list[float]): A list of floats\n",
        "\n",
        "    Returns:\n",
        "        The similarity of the two vectors a and b described as a float between 0 and 1\n",
        "    \n",
        "    \"\"\"\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def search_database(query: str, database: list[list[list[float]], str], top_k: int=1):\n",
        "    \"\"\"\n",
        "    Searches the database for the most similar documents to the query\n",
        "\n",
        "    Args:\n",
        "        query (str): The query to search for\n",
        "        database (list[list[list[float]], str]): The database to search in\n",
        "        top_k (int): The number of documents to return\n",
        "    Returns:\n",
        "        A list of the top_k most similar documents to the query\n",
        "    \"\"\"\n",
        "    query_embedding = create_embedding(query)\n",
        "    results = []\n",
        "    for (doc_embedding, doc) in database:\n",
        "        similarity = cosine_similarity(query_embedding, doc_embedding)\n",
        "        results.append((similarity, doc))\n",
        "    return sorted(results, reverse=True)[:top_k]\n",
        "\n",
        "search_database(\"Who is the CTO of Cogito?\", database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4yWzB9s9caE"
      },
      "source": [
        "### **Task 4.1**\n",
        "*Create a new embedding with some text of your choice, and add it to the database. See if you can make the model find it.*\n",
        "\n",
        "<details>\n",
        "    <summary><strong>Hint:</strong></summary>\n",
        "      - Look at the previous two cells\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g-1zWV3u--Ih"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is the capital of Norway?\n",
            "The AI gave the answer: [(np.float64(0.9420935992834718), 'The capital of Norway is Oslo.')]\n",
            "\n",
            "[SUCCESS] Shut down\n"
          ]
        }
      ],
      "source": [
        "# TODO: Create an embedding for some text and append it to the database\n",
        "corresponding_text_3 = \"The capital of Norway is Oslo.\"\n",
        "embedding_3 = create_embedding(corresponding_text_3)\n",
        "database.append([embedding_3, corresponding_text_3])\n",
        "\n",
        "while True:\n",
        "  user_input: str = input(\"What would you like to ask the model: \")\n",
        "\n",
        "  if user_input == \"q\":\n",
        "      print(\"[SUCCESS] Shut down\")\n",
        "      break\n",
        "  print(user_input)\n",
        "  answer = search_database(user_input, database, top_k=1)\n",
        "\n",
        "  print(f\"The AI gave the answer: {answer}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw5KIpeihb6B"
      },
      "source": [
        "## Part 5: Function Calling (35 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vsalQXOSh1N"
      },
      "source": [
        "Example of Yr application using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JiJQuCniheLG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\simen\\AppData\\Local\\Temp\\ipykernel_21236\\984294257.py:70: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
            "C:\\Users\\simen\\AppData\\Local\\Temp\\ipykernel_21236\\984294257.py:73: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent_chain = initialize_agent(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I can use the \"Weather at location\" tool to get the weather at the specified latitude and longitude. Then, I can calculate the average temperature from the weather data.\n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Weather at location\",\n",
            "  \"action_input\": {\n",
            "    \"latitude\": 63.41710242319078,\n",
            "    \"longitude\": -10.4066603487495\n",
            "  }\n",
            "}\n",
            "```\n",
            "\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\simen\\AppData\\Local\\Temp\\ipykernel_21236\\984294257.py:47: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  plt.legend()\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m{\"type\":\"Feature\",\"geometry\":{\"type\":\"Point\",\"coordinates\":[-10.4067,63.4171,0]},\"properties\":{\"meta\":{\"updated_at\":\"2025-11-07T09:17:15Z\",\"units\":{\"air_pressure_at_sea_level\":\"hPa\",\"air_temperature\":\"celsius\",\"cloud_area_fraction\":\"%\",\"precipitation_amount\":\"mm\",\"relative_humidity\":\"%\",\"wind_from_direction\":\"degrees\",\"wind_speed\":\"m/s\"}},\"timeseries\":[{\"time\":\"2025-11-07T10:00:00Z\",\"data\":{\"instant\":{\"details\":{\"air_pressure_at_sea_level\":1002.6,\"air_temperature\":7.5,\"cloud_area_fraction\":100.0,\"relative_humidity\":89.7,\"wind_from_direction\":69.9,\"wind_speed\":13.0}},\"next_12_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{}},\"next_1_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{\"precipitation_amount\":0.0}},\"next_6_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{\"precipitation_amount\":0.1}}}},{\"time\":\"2025-11-07T11:00:00Z\",\"data\":{\"instant\":{\"details\":{\"air_pressure_at_sea_level\":1002.8,\"air_temperature\":7.5,\"cloud_area_fraction\":100.0,\"relative_humidity\":90.7,\"wind_from_direction\":70.0,\"wind_speed\":12.6}},\"next_12_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{}},\"next_1_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{\"precipitation_amount\":0.0}},\"next_6_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{\"precipitation_amount\":0.1}}}},{\"time\":\"2025-11-07T12:00:00Z\",\"data\":{\"instant\":{\"details\":{\"air_pressure_at_sea_level\":1003.0,\"air_temperature\":7.7,\"cloud_area_fraction\":100.0,\"relative_humidity\":91.0,\"wind_from_direction\":69.0,\"wind_speed\":11.3}},\"next_12_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{}},\"next_1_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{\"precipitation_amount\":0.0}},\"next_6_hours\":{\"summary\":{\"symbol_code\":\"cloudy\"},\"details\":{\"precipitation_amount\":0.0}}}},{\"time\":\"2025-11-07T13:00:00Z\",\"data\":{\"instant\":{\"details\":{\"air_pressure_at_sea_level\":1003.3,\"air_temperature\":8.0,\"cloud_area_fraction\":100.0,\"relative_humidity\":91.4,\"wind_from_direction\":67.0,\"wind_speed\":9.8}},\"next_12_hours\":{\"summar\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAction:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Find average temperature\",\n",
            "  \"action_input\": {\n",
            "    \"temperatures\": [7.5, 7.5, 7.7, 8.0]\n",
            "  }\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m7.675\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The average temperature at the specified location is 7.675 degrees Celsius.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"The average temperature at the specified location is 7.675 degrees Celsius.\"\\n}'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "# Give the agent a list of tools to use\n",
        "def get_weather(latitude: float, longitude: float) -> str:\n",
        "    \"\"\"\n",
        "    Narrate the story based on the given prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    url = f\"https://api.met.no/weatherapi/locationforecast/2.0/compact?lat={latitude}&lon={longitude}\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (compatible; LangChain/1.0; +https://langchain.ai/)'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    plot_weather_data(response.text)\n",
        "\n",
        "    # Cap the response at 2000 characters\n",
        "    response = response.text[:2000]\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def plot_weather_data(weather_data):\n",
        "        # Parse the JSON data\n",
        "        data = json.loads(weather_data)\n",
        "\n",
        "        # Extract the temperature data from nested JSON\n",
        "        temperatures = [data['properties']['timeseries'][i]['data']['instant']['details']['air_temperature'] for i in range(len(data['properties']['timeseries']))]\n",
        "\n",
        "        # Get the temperature at every round hour\n",
        "        temperatures = temperatures[::2]\n",
        "\n",
        "        if len(temperatures) > 24:\n",
        "            temperatures = temperatures[:24]\n",
        "\n",
        "        # Plot the data\n",
        "        plt.plot(temperatures, 'r-')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Temperature (C)')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def average_temperature(temperatures: list[float]) -> float:\n",
        "    \"\"\"Return average temperature from a list of floats.\"\"\"\n",
        "    return sum(temperatures) / len(temperatures)\n",
        "\n",
        "\n",
        "tools: list[StructuredTool] = [\n",
        "    StructuredTool.from_function(\n",
        "        name= \"Weather at location\",\n",
        "        func=get_weather,\n",
        "        description=\"Get the weather at a location given a latitude and longitude.\",\n",
        "    ),\n",
        "    StructuredTool.from_function(\n",
        "        name= \"Find average temperature\",\n",
        "        func=average_temperature,\n",
        "        description=\"Get average temperature from a list of temperatures\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Make a memory for the agent to use\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "def run_agent(prompt: str) -> str:\n",
        "    \"\"\"Run the agent chain.\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        raise TypeError(\"Prompt must be a string.\")\n",
        "\n",
        "    if (len(prompt) < 1) or (len(prompt) > 1000):\n",
        "        raise ValueError(\"Prompt must be at least 1 character or less than 1000 characters.\")\n",
        "\n",
        "    result = agent_chain.invoke({\"input\": prompt})\n",
        "    return result[\"output\"]\n",
        "\n",
        "run_agent(\"Give me the weather at lat 63.41710242319078, long -10.4066603487495 and get the average temperature\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOq8xApISqe1"
      },
      "source": [
        "#### Task 5.1\n",
        "*Create your own function for dividing two numbers and add it to the AI model tools. \n",
        "Try to ask it to do several additions or a combination of dividings and additions.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "itPrDSoSSm5k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\simen\\AppData\\Local\\Temp\\ipykernel_21236\\1012527225.py:55: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = agent_chain.run(prompt)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I can use the \"Divide two numbers\" tool to calculate the result of dividing 10 by 2.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Divide two numbers\",\n",
            "  \"action_input\": {\"a\": 10, \"b\": 2}\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m5.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI can provide the final answer now.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The result of dividing 10 by 2 is 5.0\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The AI gave the answer: The result of dividing 10 by 2 is 5.0\n",
            "\n",
            "[SUCCESS] Shutting down...\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two numbers\"\"\"\n",
        "    return a + b\n",
        "\n",
        "# TODO: Create the divide function:\n",
        "\n",
        "def divide(a:int, b:int) -> float: \n",
        "    \"\"\"Divide the first number by the second number, if the second number is not zero.\"\"\"\n",
        "    if b == 0: \n",
        "        raise ValueError()\n",
        "    return a / b\n",
        "\n",
        "# TODO: Give the agent the new StructuredTool to use\n",
        "tools: list[StructuredTool] = [\n",
        "    StructuredTool.from_function(\n",
        "        name= \"Add two numbers\",\n",
        "        func=add,\n",
        "        description=\"Adds two numbers together.\",\n",
        "    ),\n",
        "    StructuredTool.from_function(\n",
        "        name = \"Divide two numbers\", \n",
        "        func = divide, \n",
        "        description=\"Divides the first number by the second number, if the second number is not zero.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Make a memorybuffer for the agent to use\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True, # Change to False if you do not want to see the chain process and only output\n",
        "    memory=memory,\n",
        "    max_iterations=3, # Number of times the model has to think about its answer\n",
        "    )\n",
        "\n",
        "def run_agent(prompt: str) -> str:\n",
        "    \"\"\"Run the agent.\"\"\"\n",
        "    if not isinstance(prompt, str):\n",
        "        raise TypeError(\"Prompt must be a string.\")\n",
        "\n",
        "    if (len(prompt) < 1) or (len(prompt) > 1000):\n",
        "        raise ValueError(\"Prompt must be at least 1 character or less than 1000 characters.\")\n",
        "\n",
        "    result = agent_chain.run(prompt)\n",
        "    return result\n",
        "\n",
        "\n",
        "while True:\n",
        "  user_input: str = input(\"What would you like to ask the model: \")\n",
        "\n",
        "  if user_input == \"q\":\n",
        "      print(\"[SUCCESS] Shutting down...\")\n",
        "      break\n",
        "\n",
        "  answer = run_agent(user_input)\n",
        "  print(f\"The AI gave the answer: {answer}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQMSdXYSyVe"
      },
      "source": [
        "#### Task 5.2\n",
        "*Work together with others and create something cool, try to utilize the different lesseons you have learned examples are:*\n",
        "* Create external API access some live data\n",
        "* Create more complex math operations to do calculus\n",
        "* Create bash scripts to create folders or organize a folder\n",
        "* Access a database for getting info\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6ClLpQnGTlcX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How did Chelsea perform in the 24/25 season in PL?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to provide the user with basic facts about Chelsea's performance in the 24/25 Premier League season.\n",
            "\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Basic facts about your team\",\n",
            "  \"action_input\": {\"team_name\": \"Chelsea\"}\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'team': 'Chelsea', 'short_name': 'CHE', 'summary': 'Chelsea — Home performance: overall rating 1180, attack 1140, defence 1220. Away performance: overall rating 1190, attack 1160, defence 1220.', 'strength_overall_home': 1180, 'strength_overall_away': 1190, 'strength_attack_home': 1140, 'strength_attack_away': 1160, 'strength_defence_home': 1220, 'strength_defence_away': 1220}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have the performance summary for Chelsea in the 24/25 Premier League season:\n",
            "\n",
            "- Home performance: Overall rating 1180, Attack 1140, Defence 1220.\n",
            "- Away performance: Overall rating 1190, Attack 1160, Defence 1220.\n",
            "\n",
            "If you need more specific details or have any other questions, feel free to ask!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Answer: I have the performance summary for Chelsea in the 24/25 Premier League season:\n",
            "\n",
            "- Home performance: Overall rating 1180, Attack 1140, Defence 1220.\n",
            "- Away performance: Overall rating 1190, Attack 1160, Defence 1220.\n",
            "\n",
            "If you need more specific details or have any other questions, feel free to ask! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: Copy relevant code from this notebook and create something\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent\n",
        "import requests \n",
        "\n",
        "def team_facts(team_name: str) -> dict: \n",
        "    \"\"\"Returns information about your team.\"\"\"\n",
        "\n",
        "    try: \n",
        "        data = requests.get(\"https://fantasy.premierleague.com/api/bootstrap-static/\").json()\n",
        "    except Exception as exception: \n",
        "        print(f\"Feilmelding: {exception}\")\n",
        "        return \n",
        "    teams = data[\"teams\"] \n",
        "    q = team_name.lower()\n",
        "    team = next(\n",
        "    (\n",
        "        t for t in teams\n",
        "        if t[\"name\"].lower() == q\n",
        "        or t[\"short_name\"].lower() == q\n",
        "        or q in t[\"name\"].lower()\n",
        "        or q in t[\"short_name\"].lower()\n",
        "    ),\n",
        "    None)\n",
        "    if not team:\n",
        "        return {\"error\": f\"No Premier League team found matching '{team_name}'.\"}\n",
        "    home_strength = team.get(\"strength_overall_home\", 0)\n",
        "    away_strength = team.get(\"strength_overall_away\", 0)\n",
        "    attack_home = team.get(\"strength_attack_home\", 0)\n",
        "    attack_away = team.get(\"strength_attack_away\", 0)\n",
        "    def_home = team.get(\"strength_defence_home\", 0)\n",
        "    def_away = team.get(\"strength_defence_away\", 0)\n",
        "\n",
        "    summary = (\n",
        "    f\"{team['name']} — Home performance: overall rating {home_strength}, \"\n",
        "    f\"attack {attack_home}, defence {def_home}. \"\n",
        "    f\"Away performance: overall rating {away_strength}, \"\n",
        "    f\"attack {attack_away}, defence {def_away}.\")\n",
        "\n",
        "    return {\n",
        "    \"team\": team[\"name\"],\n",
        "    \"short_name\": team[\"short_name\"],\n",
        "    \"summary\": summary,\n",
        "    \"strength_overall_home\": home_strength,\n",
        "    \"strength_overall_away\": away_strength,\n",
        "    \"strength_attack_home\": attack_home,\n",
        "    \"strength_attack_away\": attack_away,\n",
        "    \"strength_defence_home\": def_home,\n",
        "    \"strength_defence_away\": def_away,}\n",
        "memory2 = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "tools: list[StructuredTool] = [\n",
        "    StructuredTool.from_function(\n",
        "        name=\"Basic facts about your team\",\n",
        "        func=team_facts,\n",
        "        description=\"Returns basic facts about your team from the 24/25 season in Premier League.\"\n",
        "    ), ]\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "agent_chain2 = initialize_agent(\n",
        "    tools, \n",
        "    llm, \n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True, \n",
        "    memory=memory2,\n",
        "    max_iterations=3,\n",
        ")\n",
        "\n",
        "def run_agent2(prompt:str) -> str: \n",
        "    \"\"\"Run the agent\"\"\"\n",
        "    if not isinstance(prompt, str) or len(prompt) > 1000: \n",
        "        print(\"Write a string that is less than 1000 characters\")\n",
        "        return \n",
        "    result = agent_chain2.run(prompt)\n",
        "    return result \n",
        "\n",
        "while True: \n",
        "    user_input: str = input(\"Ask your question: \")\n",
        "    if user_input == \"q\":\n",
        "        break \n",
        "    print(user_input)\n",
        "    print(f\"Answer: {run_agent2(user_input)} \\n\") \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq8bhGmey8h9"
      },
      "source": [
        "## Extras (out of this workshops scope):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6shmlVr_Yd6"
      },
      "source": [
        "### Creating an API key\n",
        "If you want to start using these models in your own applications you will need to create a user at OpenAI, create an API key and add credits.\n",
        "[Create API key here](https://platform.openai.com/api-keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Coyz5uZE1vYd"
      },
      "source": [
        "\n",
        "### Running local LLMs\n",
        "For those interested in experimenting with Large Language Models (LLMs) without incurring the costs associated with API calls to services like OpenAI's, or dealing with sensitive or proprietary data, running pre-trained models on your own hardware presents a viable alternative. The open-source community, particularly [Hugging Face's](https://huggingface.co/models) Transformers library, offers access to a wide range of models, including some developed by leading tech companies.\n",
        "\n",
        "One of the standout models available is Google's FLAN-T5-XL, part of the T5 (Text-to-Text Transfer Transformer) family, which has been fine-tuned for a broad set of tasks. This model combines the flexibility of T5's architecture with training on a mixture of supervised and unsupervised tasks, making it particularly adept at understanding and generating human-like text.\n",
        "\n",
        "To get started with using FLAN-T5-XL or any other model from the Transformers library, you will need to install the necessary packages and understand how to load and interact with the model. Below is a basic Python script that demonstrates how to set up and use FLAN-T5-XL for generating text based on input prompts:\n",
        "```python\n",
        "import sys\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig\n",
        "\n",
        "line = 'What is the value of being accepted into Cogito NTNU, Norway's largest technical AI student organisation, in the middle of an AI revolution?'\n",
        "\n",
        "model_name = 'google/flan-t5-xl'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "config = GenerationConfig(max_new_tokens=200)\n",
        "for line in sys.stdin:\n",
        "    tokens = tokenizer(line, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**tokens, generation_config=config)\n",
        "    print(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3nKpepS9Xmw"
      },
      "source": [
        "### Context windows\n",
        "\n",
        "The context window refers to the maximum amount of text (measured in tokens) the model can consider at one time when generating responses or performing tasks. This limit is intrinsic to the model's architecture and significantly influences how we design prompts and interpret model outputs.\n",
        "\n",
        "#### Significance of the Context Window\n",
        "The size of the context window determines how much information the model can \"see\" and use at any given moment. For example, GPT-3 has a context window of 2048 tokens. This means it can consider up to 2048 tokens of preceding text to generate its responses. The implications are twofold:\n",
        "\n",
        "* **Prompt Design:** When crafting prompts for an LLM, it's vital to ensure that the most relevant information is within the model's context window. Information beyond this limit won't influence the model's output, emphasizing the need for concise and focused prompt design.\n",
        "\n",
        "* **Sequential Tasks:** For tasks requiring more information than the context window allows, you may need to design a series of prompts that build on each other, ensuring each segment of the task remains within the model's view.\n",
        "\n",
        "While advancements have led to models supporting context windows surpassing 100,000 tokens (gpt-4 and other open source ones), challenges persist. Specifically, such models tend to focus on the beginning and end of the provided text, potentially underutilizing the middle portion. This is know as [lost in the middle](https://arxiv.org/pdf/2307.03172.pdf).\n",
        "\n",
        "#### New insights by a Operative System inspired model\n",
        "[MemGPT](https://memgpt.readme.io/docs/index) introduces a strategic approach to memory management, organized around two core concepts relevant to understanding context windows in LLMs:\n",
        "\n",
        "* **Memory Hierarchy:** It segments memory into two types: a \"main context\" analogous to RAM, which is smaller and faster, and an \"external context\" similar to disk storage, which is larger but slower. This structure necessitates the deliberate transfer of information between these contexts, using virtual memory.\n",
        "\n",
        "* **Process Management:** Similar to an operating system's role in managing tasks, MemGPT regulates the flow of information between the memory segments, the LLM, and users, ensuring efficient handling of processes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc8BDSKT1y-C"
      },
      "source": [
        "### Fine-tuning Large Language Models\n",
        "Fine-tuning is a process that adjusts a pre-trained model to a specific task or dataset, enhancing its ability to perform on tasks it wasn't specifically trained for initially. This method leverages the general understanding that the model has developed during its initial training phase, applying it to a more focused domain or problem set. Fine-tuning can significantly improve the performance of LLMs on specialized tasks, making it a powerful tool for developers and researchers.\n",
        "\n",
        "#### Why Fine-tune?\n",
        "Customization: Tailors the model to understand and generate responses based on specific jargon, styles, or formats unique to your dataset.\n",
        "Improved Performance: Enhances the model's accuracy and efficiency on tasks that may differ from the data it was originally trained on.\n",
        "Cost-Effectiveness: Utilizes the foundational knowledge the model has gained, reducing the need for training from scratch on vast datasets.\n",
        "\n",
        "1. **How to Fine-tune an LLM:**\n",
        "Select a Pre-trained Model: Choose a model that closely aligns with your task in terms of language and domain. Models available on platforms like Hugging Face offer a good starting point.\n",
        "\n",
        "2. **Prepare Your Dataset:** Your dataset should be representative of the task at hand and formatted in a way that the model can understand. It typically involves splitting the data into training, validation, and test sets.\n",
        "\n",
        "3. **Customize Training Parameters:** Adjust parameters such as learning rate, batch size, and the number of epochs to balance between retaining learned knowledge and adapting to the new dataset.\n",
        "\n",
        "4. **Train the Model:** Use a suitable environment and framework, like PyTorch or TensorFlow, along with Hugging Face's Transformers library, to fine-tune the model on your dataset.\n",
        "\n",
        "5. **Evaluate and Iterate:** Test the model's performance on a separate validation set, and iteratively adjust your approach based on the results.\n",
        "\n",
        "An example of this using OpenAI can be found in the Cogito Project [MarketingAI](https://github.com/CogitoNTNU/MarketingAI/blob/main/src/fine_tuning/fine_tuning_job.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht-CtKNT7w8v"
      },
      "source": [
        "### Leveraging OpenAI Across Diverse Programming Environments\n",
        "While this course primarily focuses on Python to interact with OpenAI's models. Thera are other supported languages. Supported languages include, but are not limited to, TypeScript/JavaScript, Java, C#, Go, C++, and PHP, alongside others like Clojure, Kotlin, Ruby, Rust, and Scala. This wide-ranging support extends the potential of OpenAI's AI models to virtually any software development domain, from web development and mobile applications to enterprise solutions and beyond.\n",
        "\n",
        "[Read more at OpenAI Docs](https://platform.openai.com/docs/libraries/community-libraries)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
