{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop om Ragas\n",
    "\n",
    "#### Kilder:\n",
    "- [RAGAS](https://docs.ragas.io/en/stable/) <img src=\"media/ragas.png\" alt=\"Ragas logo\" width=\"25\"/>\n",
    "\n",
    "## Begrepsforklaringer\n",
    "##### RAG\n",
    "RAG står for Retrieval-Augmented Generation og gir generativ kunstig intelligens modeler informasjonsinnhenting muligheter. Dette betyr RAG-en hjelper generative KI ved å gi den tilgang til relevant informasjon som kan hjelpe med å svare på spørsmål fra bruker. \n",
    "Informasjonen blir på forhånd lagret omgjort til LLM-embeddings (store vektorer) og lagret i vektor-databaser. Før den generative KI-en svarer, blir brukerspørsmålet gjort om til en egen LLM-embedding og den embeddingen blir brukt til å sammenligne med de andre vektorene i vektor-databasen. Her blir ofte \"Cosine-similarity\" brukt for å finne vektorene som ligner mest. Deretter blir informasjonen som er mest relevant til spørsmålet, gitt til KI-en.\n",
    "\n",
    "### Hva er ragas?\n",
    "Ragas er et bra dokumentert (!), open-source bibliotek som lar deg evaluere LLM-applikasjoner og RAG-er. Viktig for denne evalueringen er metrics.\n",
    "\n",
    "<img src=\"media/metrics_mindmap.png\" alt=\"Metrics Mindmap\" width=\"500\"/>\n",
    "\n",
    "To typer metrics:\n",
    "\n",
    "##### LLM Based\n",
    "- Bruker LLM til å vurdere. \n",
    "- Non-deterministisk ved at LLM ikke alltid vil returnere det samme resultatet\n",
    "- Likevel vist seg å være mer nøyaktige og nærmere menneskelig evaluering\n",
    "\n",
    "##### Non-LLM Based\n",
    "- Bruker **ikke** LLM til å vurdere\n",
    "- Deterministiske \n",
    "- Bruker tradisjonelle metoder for å evaluere\n",
    "- Mindre nøyaktige sammenlignet med menneskelig evaluering\n",
    "\n",
    "\n",
    "To andre kategorier:\n",
    "##### Single Turn Metrics\n",
    "- Evaluerer basert på én runde med interaksjon mellom bruker og generativ KI\n",
    "\n",
    "##### Multiple Turn Metrics\n",
    "- Evalierer basert på flere runder med interaksjon mellom bruker og generativ KI\n",
    "\n",
    "\n",
    "### Hvordan evaluere med Ragas?\n",
    "For å evaluere hvor god en generativ KI trenger man 3 ting:\n",
    "- Spørsmål\n",
    "- Svar\n",
    "- Referanse/riktig svar\n",
    "\n",
    "Med dette kan man evaluere om svaret KI-en gir stemmer opp mot svaret vi forventer.\n",
    "\n",
    "For å evaluere hvor god en RAG er til å gi riktig informasjon til KI-en trenger man 4 ting:\n",
    "- Spørsmål\n",
    "- Svar\n",
    "- Referanse/riktig svar\n",
    "- Gitt kontekst/informasjon\n",
    "\n",
    "Den siste (gitt kontekst) er viktig når man skal vurdere hvor svikten i system ligger. Hvis det er gitt feil kontekst, er det RAG-en som har mislyktes. Hvis det er riktig kontekst, men feil svar, er det KI-en som har mislyktes. \n",
    "\n",
    "Under skal vi se hvordan vi kan evaluere en RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.3.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: langchain in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.31)\n",
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp311-cp311-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (2.3.2)\n",
      "Collecting datasets (from ragas)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (0.11.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (0.3.74)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (0.3.27)\n",
      "Collecting typer (from ragas)\n",
      "  Downloading typer-0.16.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting rich (from ragas)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ragas) (1.101.0)\n",
      "Collecting instructor (from ragas)\n",
      "  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitpython (from ragas)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pillow>=10.4.0 (from ragas)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.4.16)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community->ragas) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community->ragas) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community->ragas) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community->ragas) (0.4.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core->ragas) (4.14.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.0.0->ragas) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.0.0->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken->ragas) (2025.7.34)\n",
      "Collecting filelock (from datasets->ragas)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->ragas)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: xxhash in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets->ragas) (3.5.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets->ragas)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->ragas)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.4 (from instructor->ragas)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->ragas)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->ragas) (2.19.2)\n",
      "Collecting click>=8.0.0 (from typer->ragas)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer->ragas)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->ragas) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->ragas)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.4->instructor->ragas)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->ragas)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\simen\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.1.0)\n",
      "Downloading ragas-0.3.2-py3-none-any.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 112.6/277.3 kB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/277.3 kB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/277.3 kB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/277.3 kB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/277.3 kB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/277.3 kB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 204.8/277.3 kB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- 277.3/277.3 kB 814.2 kB/s eta 0:00:00\n",
      "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 20.5/209.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 20.5/209.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 20.5/209.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 20.5/209.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 20.5/209.2 kB ? eta -:--:--\n",
      "   --------------------------- ---------- 153.6/209.2 kB 541.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 209.2/209.2 kB 637.5 kB/s eta 0:00:00\n",
      "Downloading faiss_cpu-1.12.0-cp311-cp311-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/18.2 MB 6.3 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.2/18.2 MB 4.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/18.2 MB 4.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/18.2 MB 4.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/18.2 MB 4.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/18.2 MB 4.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.3/18.2 MB 853.3 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.9/18.2 MB 1.3 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.9/18.2 MB 1.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.9/18.2 MB 1.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.9/18.2 MB 1.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.9/18.2 MB 1.3 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 1.3/18.2 MB 1.5 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.6/18.2 MB 1.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 2.4/18.2 MB 2.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 3.3/18.2 MB 3.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 4.1/18.2 MB 3.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 4.2/18.2 MB 3.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 4.5/18.2 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 5.2/18.2 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 5.7/18.2 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 6.3/18.2 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 6.3/18.2 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 6.7/18.2 MB 4.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.3/18.2 MB 5.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.4/18.2 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.8/18.2 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 8.4/18.2 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 8.5/18.2 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 9.4/18.2 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 9.5/18.2 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 10.3/18.2 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 10.5/18.2 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 11.0/18.2 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 11.5/18.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 11.7/18.2 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.5/18.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 13.3/18.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 14.1/18.2 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 15.3/18.2 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.3/18.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.8/18.2 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.8/18.2 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.2/18.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.2/18.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.3 MB 32.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.8/11.3 MB 22.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/11.3 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.8/11.3 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.8/11.3 MB 21.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.3 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.7/11.3 MB 21.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.4/11.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 20.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.3/11.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.3/11.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.2/11.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.5/45.5 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading pillow-11.3.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.7/7.0 MB 21.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.6/7.0 MB 20.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.5/7.0 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.5/7.0 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.4/7.0 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/7.0 MB 19.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.1/7.0 MB 19.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.0/7.0 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "   ---------------------------------------- 0.0/509.2 kB ? eta -:--:--\n",
      "   --------------------------------------  501.8/509.2 kB 15.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 509.2/509.2 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "   ---------------------------------------- 0.0/347.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 347.8/347.8 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "   ---------------------------------------- 0.0/494.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 494.8/494.8 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "   ---------------------------------------- 0.0/208.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 208.2/208.2 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading instructor-1.10.0-py3-none-any.whl (119 kB)\n",
      "   ---------------------------------------- 0.0/119.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 119.5/119.5 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.4 kB ? eta -:--:--\n",
      "   ------------------------------------- - 235.5/243.4 kB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 243.4/243.4 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading typer-0.16.1-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.4/46.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.2/102.2 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.3/116.3 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 193.6/193.6 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   ------------------------------------- - 542.7/561.5 kB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 561.5/561.5 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.9/134.9 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.3/87.3 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.5/143.5 kB 8.3 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.9/26.2 MB 18.7 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.8/26.2 MB 19.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.8/26.2 MB 19.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.7/26.2 MB 19.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.6/26.2 MB 19.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.6/26.2 MB 19.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.4/26.2 MB 19.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/26.2 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 8.1/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.1/26.2 MB 20.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.0/26.2 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.9/26.2 MB 19.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.8/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.6/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.4/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.3/26.2 MB 19.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.2/26.2 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.0/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.9/26.2 MB 19.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.7/26.2 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.7/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.6/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.5/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.4/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.2/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.1/26.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.1/26.2 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, appdirs, tzdata, smmap, shellingham, pyarrow, pillow, mdurl, MarkupSafe, fsspec, filelock, faiss-cpu, docstring-parser, diskcache, dill, click, pandas, multiprocess, markdown-it-py, jinja2, huggingface-hub, gitdb, rich, gitpython, typer, datasets, instructor, ragas, langchain_experimental\n",
      "Successfully installed MarkupSafe-3.0.2 appdirs-1.4.4 click-8.2.1 datasets-4.0.0 dill-0.3.8 diskcache-5.6.3 docstring-parser-0.17.0 faiss-cpu-1.12.0 filelock-3.19.1 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.45 huggingface-hub-0.34.4 instructor-1.10.0 jinja2-3.1.6 langchain_experimental-0.3.4 markdown-it-py-4.0.0 mdurl-0.1.2 multiprocess-0.70.16 pandas-2.3.2 pillow-11.3.0 pyarrow-21.0.0 pytz-2025.2 ragas-0.3.2 rich-14.1.0 shellingham-1.5.4 smmap-5.0.2 typer-0.16.1 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\simen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ragas langchain langchain_openai langchain_experimental faiss-cpu pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sette env-variabler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://eu.api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Ragas Tutorial\"\n",
    "LANGSMITH_API_KEY = os.environ.get(\"LANGSMITH_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lese fil og lage vektor-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"0\"\n",
    "from ragas import EvaluationDataset\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter, MarkdownTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_core.documents import Document\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, ContextEntityRecall, ContextPrecision, Faithfulness\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from ragas.utils import safe_nanmean\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Setter opp RAG-en\n",
    "\n",
    "# Leser dokumentene vi vil legge inn i RAG-en\n",
    "filepath = 'data/dnd_doc.md'\n",
    "\n",
    "\n",
    "dnd_document: str = \"\"\n",
    "with open(filepath, encoding=\"utf-8\") as f:\n",
    "    dnd_document = f.read()\n",
    "\n",
    "# Gjør teksten om til en Document-klasse fra Langchain\n",
    "dnd_document = [Document(dnd_document)]\n",
    "\n",
    "# Splitter dokumentet med en tekstsplitter fra Langchain\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) # TextSplitter\n",
    "splits = text_splitter.split_documents(dnd_document)\n",
    "# Lager en vektor-database retriever\n",
    "k = 3\n",
    "score_threshold = 0.6\n",
    "vector_retriever = FAISS.from_documents(splits, OpenAIEmbeddings()).as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs = {\n",
    "                \"k\": k,\n",
    "                \"score_threshold\": score_threshold\n",
    "                }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generere svar til spørsmålene i CSV-filen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model= \"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            max_tokens=16384\n",
    "        )\n",
    "\n",
    "def convert_docs_to_strings(docs: list[Document]) -> list[str]:\n",
    "        \"\"\"Convert Objects of Document type to an list of strings\"\"\"\n",
    "        return [doc.page_content for doc in docs]\n",
    "\n",
    "def get_relevant_docs(query: str) -> list[str]:\n",
    "    return convert_docs_to_strings(vector_retriever.invoke(input=query))\n",
    "\n",
    "def generate_answer(query: str, relevant_doc: list[Document]):\n",
    "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
    "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
    "        messages = [\n",
    "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
    "            (\"human\", prompt),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        return ai_msg.content\n",
    "\n",
    "dataset = []\n",
    "\n",
    "df = pd.read_csv(\"data/sample_questions_dnd.csv\")\n",
    "querys = df[\"question\"].tolist()\n",
    "responses = df[\"answer\"].tolist()\n",
    "\n",
    "for query, reference in zip(querys, responses):\n",
    "\n",
    "    relevant_docs = get_relevant_docs(query=query)\n",
    "    response = generate_answer(query, relevant_docs)\n",
    "    # Legger til i datasettet spørsmålet, kontekst, response fra KI og referansen/riktig svar\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluere datasettet\n",
    "For å evaluere datasettet kan man bruke mange ulike metrics, alle listet på nettsiden til Ragas (https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/)\n",
    "\n",
    "- Context Precision\n",
    "- Context Recall\n",
    "- Context Entities Recall\n",
    "- Noise Sensitivity\n",
    "- Response Relevancy\n",
    "- Faithfulness\n",
    "- Multimodal Faithfulness\n",
    "- Multimodal Relevance\n",
    "- Factual Correctness\n",
    "- Semantic Similarity\n",
    "- Non LLM String Similarity\n",
    "- BLEU Score\n",
    "- ROUGE Score\n",
    "- String Presence\n",
    "- Exact Match\n",
    "\n",
    "Her kommer vi til å bruke to til å vurdere RAG-en (Context Recall og Context Precision) og en for å vurdere responsen til LLM-en (Factual Correctness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [00:37<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.874999999924074 0.8740740740740741\n"
     ]
    }
   ],
   "source": [
    "# Evaluerer datasettet\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), ContextPrecision(), Faithfulness()],\n",
    "    llm=evaluator_llm\n",
    ")\n",
    "\n",
    "context_recall = safe_nanmean(result[\"context_recall\"])\n",
    "context_precision = safe_nanmean(result[\"context_precision\"])\n",
    "faithfulness = safe_nanmean(result[\"faithfulness\"])\n",
    "\n",
    "print(context_recall, context_precision, faithfulness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste ulike parametere for å finne beste kombinasjon for RAG-en\n",
    "Basert på resultatene kan vi forbedre RAG-en ved å endre på ulike aspekter av RAG-en. Det er to måter måter man kan gjøre det på:\n",
    "\n",
    "#### Splitters\n",
    "\n",
    "Det første aspektet er hvordan vi deler opp dokumentet før vi legger det inn i databasen. Med klassen RecursiveCharacterSplitter kan vi endre på hvor store chunks vi lager og hvor mye overlap de har. Dette bestemmer hvor mye informasjon det er i hver kontekst vi gir LLM-en. \n",
    "\n",
    "Mindre kontekst:\n",
    "- Mindre informasjon til LLM-en per spørring\n",
    "- Kan svekke nøyaktigheten noe, \n",
    "- Krever mindre tokens. \n",
    "\n",
    "Større kontekst:\n",
    "- Mer informasjon til LLM-en\n",
    "- Kan øke nøyaktigheten\n",
    "- Krever mer tokens\n",
    "\n",
    "Man kan også bruke andre splittere (eller lage egne). Her er andre splittere fra Langchain som kan brukes:\n",
    "- CharacterTextSplitter\n",
    "- MarkdownHeaderTextSplitter\n",
    "- RecursiveJsonSplitter\n",
    "- SemanticChunker\n",
    "\n",
    "#### Retrivers (vektordatabase)\n",
    "Hvordan dataen blir lagret og hvordan den blir hentet er mye å si på nøyaktigheten til RAG-en. Med FAISS som vectorstore er det tre parametere man kan endre på:\n",
    "- Search Type\n",
    "   - similarity\n",
    "   - similiarity_score_threshold\n",
    "   - mmr\n",
    "- k\n",
    "    - Maksimalt antall kontekster som blir hentet\n",
    "\n",
    "- score_threshold\n",
    "    - Likhetsscore for at en kontekst skal kunne bli hentet av k\n",
    "\n",
    "Man kan også bruke andre måter å hente dokumenter på. I tillegg til egen implementerte metoder, har Langchain flere ulike retrievers:\n",
    "- ParentDocumentRetriever, \n",
    "- EnsembleRetriever \n",
    "- MultiVectorRetriever\n",
    "- BM25Retriver\n",
    "\n",
    "\n",
    "\n",
    "##### Prøv dere fram og forsøk å få høyest mulig score!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [00:55<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cs=1000, co=100, k=3, th=0.6] -> 1.0 0.8680555554809026 0.8601851851851853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [00:41<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cs=800, co=100, k=3, th=0.6] -> 0.9722222222222222 0.8796296295590277 0.8402777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [01:16<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cs=1000, co=100, k=5, th=0.6] -> 1.0 0.8451774690672101 0.8675925925925925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 108/108 [00:36<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cs=1000, co=100, k=3, th=0.7] -> 0.9722222222222222 0.8564814814085646 0.9004629629629629\n",
      "\n",
      "Best config: {'chunk_size': 1000, 'chunk_overlap': 100, 'k': 3, 'score_threshold': 0.7, 'context_recall': 0.9722222222222222, 'context_precision': 0.8564814814085646, 'faithfulness': 0.9004629629629629}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    # (chunk_size, chunk_overlap, k, score_threshold)\n",
    "    (1000, 100, 3, 0.6),\n",
    "    (800,  100, 3, 0.6),\n",
    "    (1000, 100, 5, 0.6),\n",
    "    (1000, 100, 3, 0.7),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for chunk_size, chunk_overlap, k, score_threshold in param_grid:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap) \n",
    "    splits = text_splitter.split_documents(dnd_document)\n",
    "\n",
    "    vector_retriever = FAISS.from_documents(splits, OpenAIEmbeddings()).as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": k,\n",
    "            \"score_threshold\": score_threshold\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dataset = []\n",
    "    for query, reference in zip(querys, responses):\n",
    "        relevant_docs = get_relevant_docs(query=query)\n",
    "        response = generate_answer(query, relevant_docs)\n",
    "        dataset.append(\n",
    "            {\n",
    "                \"user_input\": query,\n",
    "                \"retrieved_contexts\": relevant_docs,\n",
    "                \"response\": response,\n",
    "                \"reference\": reference\n",
    "            }\n",
    "        )\n",
    "\n",
    "    evaluation_dataset = EvaluationDataset.from_list(dataset)\n",
    "    evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "    result = evaluate(\n",
    "        dataset=evaluation_dataset,\n",
    "        metrics=[LLMContextRecall(), ContextPrecision(), Faithfulness()],\n",
    "        llm=evaluator_llm\n",
    "    )\n",
    "\n",
    "    context_recall = safe_nanmean(result[\"context_recall\"])\n",
    "    context_precision = safe_nanmean(result[\"context_precision\"])\n",
    "    faithfulness = safe_nanmean(result[\"faithfulness\"])\n",
    "\n",
    "    print(f\"[cs={chunk_size}, co={chunk_overlap}, k={k}, th={score_threshold}] ->\",\n",
    "          context_recall, context_precision, faithfulness)\n",
    "\n",
    "    results.append({\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"chunk_overlap\": chunk_overlap,\n",
    "        \"k\": k,\n",
    "        \"score_threshold\": score_threshold,\n",
    "        \"context_recall\": context_recall,\n",
    "        \"context_precision\": context_precision,\n",
    "        \"faithfulness\": faithfulness\n",
    "    })\n",
    "\n",
    "best = max(results, key=lambda r: (r[\"faithfulness\"], r[\"context_precision\"], r[\"context_recall\"]))\n",
    "print(\"\\nBest config:\", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Hvis tid\n",
    "## Optuna\n",
    "Et bibliotek for å automatisere testing av parametere. Man spesifiserer en oppgave med ulike parametere (som bygging av en RAG) og sier hvilke verdier som den skal prøve å forbedre (for eksempel Context Recall fra RAGAS). Dette kan gjentas så mange ganger man vil og kan pararalliseres. Til slutt kan resultatene fra utprøvingen vises i Optuna sitt eget dashboard.\n",
    "\n",
    "Se filen **optuna_test.py** for kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U optuna optuna-dashboard optunahub logging cmaes torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
